{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f125c7d-a1eb-4c78-9a06-4fde14f3abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3281ea-6d1c-4776-b8bd-e1cb71e61ec6",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbc4f42-4598-42d7-9f23-fd7ec789c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50    # steepness factor\n",
    "num_blocks = 1    # number of expression blocks\n",
    "num_data = 9100   # number of data\n",
    "test_size = 100   # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0aa025-af27-4c59-b1ef-6d6eca211a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74827cd-4e92-42d2-a890-9df73742bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66733bc-1888-4641-bea0-81c92701e027",
   "metadata": {},
   "source": [
    "## Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9575a5-e610-4aec-936a-f063923ef95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5018e7f-1346-4f4e-8961-f1613e2d2721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.27626589]), array([-1.85462808]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(17)\n",
    "b = rng.normal(scale=1, size=(num_blocks))\n",
    "q = rng.normal(scale=1, size=(num_blocks))\n",
    "b, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "717358ec-fa7a-4156-9efe-0c1fe2d3bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"p\":p_test[0], \"a\":a_test[0]}\n",
    "model.set_param_val(params)\n",
    "solvals, objval = model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9d936f7-70c5-4fab-afc4-de646ebb5234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {0: -1.9926868120184897, 1: 4.0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05a0509d-cc6a-4a1c-9c64-b11cf5d5e0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.89757056905451"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037fe94-d6cd-4b74-b14b-db34fb3d9538",
   "metadata": {},
   "source": [
    "## Learnable Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9dbceb-2e32-4530-8292-7bbfbdbc7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de58418-375d-48be-8b42-56f7253a3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 4             # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c112efa1-fa93-48df-957b-1694d0b8ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d941ac-4cec-4a51-8102-881200e23d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 633.96\n",
      "Epoch 1, Validation Loss: 563.72\n",
      "Epoch 2, Validation Loss: 52.03\n",
      "Epoch 3, Validation Loss: 39.96\n",
      "Epoch 4, Validation Loss: 37.59\n",
      "Epoch 5, Validation Loss: 37.05\n",
      "Epoch 6, Validation Loss: 37.39\n",
      "Epoch 7, Validation Loss: 35.72\n",
      "Epoch 8, Validation Loss: 38.21\n",
      "Epoch 9, Validation Loss: 36.76\n",
      "Epoch 10, Validation Loss: 38.36\n",
      "Epoch 11, Validation Loss: 33.15\n",
      "Epoch 12, Validation Loss: 32.57\n",
      "Epoch 13, Validation Loss: 31.43\n",
      "Epoch 14, Validation Loss: 31.64\n",
      "Epoch 15, Validation Loss: 30.14\n",
      "Epoch 16, Validation Loss: 28.77\n",
      "Epoch 17, Validation Loss: 30.81\n",
      "Epoch 18, Validation Loss: 28.81\n",
      "Epoch 19, Validation Loss: 28.83\n",
      "Epoch 20, Validation Loss: 29.86\n",
      "Epoch 21, Validation Loss: 30.51\n",
      "Epoch 22, Validation Loss: 30.46\n",
      "Epoch 23, Validation Loss: 30.96\n",
      "Epoch 24, Validation Loss: 30.43\n",
      "Epoch 25, Validation Loss: 30.27\n",
      "Epoch 26, Validation Loss: 29.60\n",
      "Epoch 27, Validation Loss: 26.59\n",
      "Epoch 28, Validation Loss: 26.70\n",
      "Epoch 29, Validation Loss: 25.62\n",
      "Epoch 30, Validation Loss: 25.23\n",
      "Epoch 31, Validation Loss: 23.51\n",
      "Epoch 32, Validation Loss: 23.90\n",
      "Epoch 33, Validation Loss: 23.90\n",
      "Epoch 34, Validation Loss: 22.81\n",
      "Epoch 35, Validation Loss: 22.76\n",
      "Epoch 36, Validation Loss: 22.61\n",
      "Epoch 37, Validation Loss: 22.68\n",
      "Epoch 38, Validation Loss: 23.13\n",
      "Epoch 39, Validation Loss: 22.88\n",
      "Epoch 40, Validation Loss: 22.37\n",
      "Epoch 41, Validation Loss: 22.16\n",
      "Epoch 42, Validation Loss: 22.37\n",
      "Epoch 43, Validation Loss: 22.07\n",
      "Epoch 44, Validation Loss: 22.06\n",
      "Epoch 45, Validation Loss: 22.22\n",
      "Epoch 46, Validation Loss: 22.14\n",
      "Epoch 47, Validation Loss: 22.10\n",
      "Epoch 48, Validation Loss: 22.05\n",
      "Epoch 49, Validation Loss: 22.23\n",
      "Epoch 50, Validation Loss: 22.28\n",
      "Epoch 51, Validation Loss: 22.18\n",
      "Epoch 52, Validation Loss: 22.03\n",
      "Epoch 53, Validation Loss: 22.06\n",
      "Epoch 54, Validation Loss: 22.47\n",
      "Epoch 55, Validation Loss: 22.15\n",
      "Epoch 56, Validation Loss: 22.09\n",
      "Epoch 57, Validation Loss: 22.19\n",
      "Epoch 58, Validation Loss: 22.19\n",
      "Epoch 59, Validation Loss: 22.04\n",
      "Epoch 60, Validation Loss: 22.03\n",
      "Epoch 61, Validation Loss: 22.19\n",
      "Epoch 62, Validation Loss: 22.20\n",
      "Epoch 63, Validation Loss: 22.06\n",
      "Epoch 64, Validation Loss: 21.97\n",
      "Epoch 65, Validation Loss: 22.25\n",
      "Epoch 66, Validation Loss: 22.15\n",
      "Epoch 67, Validation Loss: 22.13\n",
      "Epoch 68, Validation Loss: 21.89\n",
      "Epoch 69, Validation Loss: 22.11\n",
      "Epoch 70, Validation Loss: 22.24\n",
      "Epoch 71, Validation Loss: 22.25\n",
      "Epoch 72, Validation Loss: 22.10\n",
      "Epoch 73, Validation Loss: 22.20\n",
      "Epoch 74, Validation Loss: 22.21\n",
      "Epoch 75, Validation Loss: 22.14\n",
      "Epoch 76, Validation Loss: 22.16\n",
      "Epoch 77, Validation Loss: 22.00\n",
      "Epoch 78, Validation Loss: 22.21\n",
      "Epoch 79, Validation Loss: 22.29\n",
      "Epoch 80, Validation Loss: 22.12\n",
      "Epoch 81, Validation Loss: 22.05\n",
      "Epoch 82, Validation Loss: 22.08\n",
      "Epoch 83, Validation Loss: 22.02\n",
      "Epoch 84, Validation Loss: 21.98\n",
      "Epoch 85, Validation Loss: 21.87\n",
      "Epoch 86, Validation Loss: 22.18\n",
      "Epoch 87, Validation Loss: 21.88\n",
      "Epoch 88, Validation Loss: 22.43\n",
      "Epoch 89, Validation Loss: 21.98\n",
      "Epoch 90, Validation Loss: 22.06\n",
      "Epoch 91, Validation Loss: 22.04\n",
      "Epoch 92, Validation Loss: 21.90\n",
      "Epoch 93, Validation Loss: 22.21\n",
      "Epoch 94, Validation Loss: 22.13\n",
      "Epoch 95, Validation Loss: 22.04\n",
      "Epoch 96, Validation Loss: 22.16\n",
      "Epoch 97, Validation Loss: 22.09\n",
      "Epoch 98, Validation Loss: 21.86\n",
      "Epoch 99, Validation Loss: 22.14\n",
      "Epoch 100, Validation Loss: 22.39\n",
      "Epoch 101, Validation Loss: 22.06\n",
      "Epoch 102, Validation Loss: 21.96\n",
      "Epoch 103, Validation Loss: 21.96\n",
      "Epoch 104, Validation Loss: 22.11\n",
      "Epoch 105, Validation Loss: 21.87\n",
      "Epoch 106, Validation Loss: 21.98\n",
      "Epoch 107, Validation Loss: 22.18\n",
      "Epoch 108, Validation Loss: 22.08\n",
      "Epoch 109, Validation Loss: 22.04\n",
      "Epoch 110, Validation Loss: 22.19\n",
      "Epoch 111, Validation Loss: 22.07\n",
      "Epoch 112, Validation Loss: 22.08\n",
      "Epoch 113, Validation Loss: 21.94\n",
      "Epoch 114, Validation Loss: 22.01\n",
      "Epoch 115, Validation Loss: 21.88\n",
      "Epoch 116, Validation Loss: 22.02\n",
      "Epoch 117, Validation Loss: 22.34\n",
      "Early stopping at epoch 117\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 196.42 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f0a203-a62b-407d-a9e5-e82e2a1b0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, a = p_test[0], a_test[0]\n",
    "datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "              \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "              \"name\": \"test\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d3e287-b84e-4bdc-b3f6-2a53ebd3f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer\n",
    "components.eval()\n",
    "with torch.no_grad():\n",
    "    for comp in components:\n",
    "        datapoints.update(comp(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7af0992-0b1d-496f-bedc-2035ffdf251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': tensor([[6.0419]], device='cuda:0'),\n",
       " 'a': tensor([[3.8258]], device='cuda:0'),\n",
       " 'name': 'test',\n",
       " 'x': tensor([[-1.1720,  2.9795]], device='cuda:0'),\n",
       " 'x_rnd': tensor([[-1.8502,  3.0000]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5f7671-1335-45c2-a46c-98c0243baebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6782,  9.4901]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, x = rnd._extract_data(datapoints)\n",
    "with torch.no_grad():\n",
    "    h = rnd.layers(torch.cat(p+x, dim=-1))\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4c355-026e-46e3-9845-ca7c513db391",
   "metadata": {},
   "source": [
    "## Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4c3b7a-fc9a-4149-ba67-bd250b42b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec950b0-630c-499a-a961-35000455ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 4             # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c80ea0a-b2db-43c2-bc04-bf7c73b498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                          int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736010cf-3172-4d5f-8abf-de4a8191b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Loss: 245.18\n",
      "Epoch 1, Validation Loss: 227.98\n",
      "Epoch 2, Validation Loss: 47.26\n",
      "Epoch 3, Validation Loss: 29.14\n",
      "Epoch 4, Validation Loss: 24.36\n",
      "Epoch 5, Validation Loss: 23.61\n",
      "Epoch 6, Validation Loss: 23.70\n",
      "Epoch 7, Validation Loss: 23.17\n",
      "Epoch 8, Validation Loss: 23.34\n",
      "Epoch 9, Validation Loss: 23.12\n",
      "Epoch 10, Validation Loss: 23.36\n",
      "Epoch 11, Validation Loss: 23.16\n",
      "Epoch 12, Validation Loss: 23.04\n",
      "Epoch 13, Validation Loss: 23.27\n",
      "Epoch 14, Validation Loss: 22.90\n",
      "Epoch 15, Validation Loss: 23.02\n",
      "Epoch 16, Validation Loss: 22.70\n",
      "Epoch 17, Validation Loss: 22.60\n",
      "Epoch 18, Validation Loss: 22.73\n",
      "Epoch 19, Validation Loss: 22.70\n",
      "Epoch 20, Validation Loss: 22.94\n",
      "Epoch 21, Validation Loss: 22.70\n",
      "Epoch 22, Validation Loss: 22.98\n",
      "Epoch 23, Validation Loss: 22.66\n",
      "Epoch 24, Validation Loss: 22.56\n",
      "Epoch 25, Validation Loss: 22.50\n",
      "Epoch 26, Validation Loss: 22.52\n",
      "Epoch 27, Validation Loss: 22.58\n",
      "Epoch 28, Validation Loss: 22.41\n",
      "Epoch 29, Validation Loss: 22.31\n",
      "Epoch 30, Validation Loss: 22.53\n",
      "Epoch 31, Validation Loss: 22.18\n",
      "Epoch 32, Validation Loss: 22.12\n",
      "Epoch 33, Validation Loss: 22.00\n",
      "Epoch 34, Validation Loss: 22.07\n",
      "Epoch 35, Validation Loss: 22.06\n",
      "Epoch 36, Validation Loss: 22.01\n",
      "Epoch 37, Validation Loss: 22.01\n",
      "Epoch 38, Validation Loss: 22.17\n",
      "Epoch 39, Validation Loss: 22.03\n",
      "Epoch 40, Validation Loss: 22.19\n",
      "Epoch 41, Validation Loss: 21.81\n",
      "Epoch 42, Validation Loss: 22.16\n",
      "Epoch 43, Validation Loss: 22.08\n",
      "Epoch 44, Validation Loss: 22.11\n",
      "Epoch 45, Validation Loss: 22.15\n",
      "Epoch 46, Validation Loss: 21.93\n",
      "Epoch 47, Validation Loss: 21.98\n",
      "Epoch 48, Validation Loss: 21.84\n",
      "Epoch 49, Validation Loss: 21.89\n",
      "Epoch 50, Validation Loss: 21.97\n",
      "Epoch 51, Validation Loss: 21.76\n",
      "Epoch 52, Validation Loss: 21.93\n",
      "Epoch 53, Validation Loss: 21.75\n",
      "Epoch 54, Validation Loss: 21.77\n",
      "Epoch 55, Validation Loss: 21.95\n",
      "Epoch 56, Validation Loss: 21.97\n",
      "Epoch 57, Validation Loss: 22.04\n",
      "Epoch 58, Validation Loss: 22.02\n",
      "Epoch 59, Validation Loss: 21.96\n",
      "Epoch 60, Validation Loss: 22.17\n",
      "Epoch 61, Validation Loss: 22.00\n",
      "Epoch 62, Validation Loss: 22.48\n",
      "Epoch 63, Validation Loss: 22.11\n",
      "Epoch 64, Validation Loss: 21.94\n",
      "Epoch 65, Validation Loss: 22.14\n",
      "Epoch 66, Validation Loss: 22.02\n",
      "Epoch 67, Validation Loss: 22.06\n",
      "Epoch 68, Validation Loss: 21.87\n",
      "Epoch 69, Validation Loss: 21.86\n",
      "Epoch 70, Validation Loss: 21.95\n",
      "Epoch 71, Validation Loss: 21.93\n",
      "Epoch 72, Validation Loss: 21.84\n",
      "Early stopping at epoch 72\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 140.13 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs, patience, warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988d2d7a-13ad-4de9-b050-ab706153b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, a = p_test[0], a_test[0]\n",
    "datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "              \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "              \"name\": \"test\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccd50cc1-7173-44b7-8b9d-342295e76536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer\n",
    "components.eval()\n",
    "with torch.no_grad():\n",
    "    for comp in components:\n",
    "        datapoints.update(comp(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747eb2e1-315b-4e30-9d11-ba8575077fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': tensor([[6.0419]], device='cuda:0'),\n",
       " 'a': tensor([[3.8258]], device='cuda:0'),\n",
       " 'name': 'test',\n",
       " 'x': tensor([[-1.1426,  3.0917]], device='cuda:0'),\n",
       " 'x_rnd': tensor([[-1.8327,  3.0000]], device='cuda:0')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c7f4007-5014-4d57-9424-9ec6bff33dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6901, -1.8398]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, x = rnd._extract_data(datapoints)\n",
    "with torch.no_grad():\n",
    "    h = rnd.layers(torch.cat(p+x, dim=-1))\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c829f3-63bc-4453-94e3-2b0f73cc5ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3340, 0.1371]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.sigmoid(h)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d96013-fe5c-454b-b4ea-d572d5094942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
