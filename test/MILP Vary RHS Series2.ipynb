{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b20ab5-c96b-4200-9d62-428fba6e090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import gzip\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa4bba7-0e7e-42e0-8d93-b4f9825f26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbff04c-8afc-43c0-a2e1-6d49c00f4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-12-25\n"
     ]
    }
   ],
   "source": [
    "# disable Gurobi output globally\n",
    "gp.setParam(\"OutputFlag\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4be44-d664-4fda-a898-f7852eba1758",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05722ed-b6ee-499d-9244-a88099138176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVarTypes(model):\n",
    "    types = []\n",
    "    for var in model.getVars():\n",
    "        # classify as binary if integer with bounds [0, 1]\n",
    "        if var.VType == GRB.INTEGER and var.LB == 0 and var.UB == 1:\n",
    "            types.append(GRB.BINARY)\n",
    "        else:\n",
    "            types.append(var.VType)\n",
    "    return types\n",
    "\n",
    "def getObjVec(model):\n",
    "    obj_vector = np.array([var.Obj for var in model.getVars()])\n",
    "    return obj_vector\n",
    "\n",
    "def getConstrMat(model):\n",
    "    num_constraints = model.NumConstrs\n",
    "    num_variables = model.NumVars\n",
    "    A_matrix = np.zeros((num_constraints, num_variables))\n",
    "    for i, constraint in enumerate(model.getConstrs()):\n",
    "        # check the sense and adjust if necessary\n",
    "        if constraint.Sense == GRB.GREATER_EQUAL:\n",
    "            # multiply the constraint row and RHS by -1 to convert >= to <=\n",
    "            row = model.getRow(constraint)\n",
    "            for j in range(row.size()):\n",
    "                var = row.getVar(j)\n",
    "                col_index = var.index\n",
    "                A_matrix[i, col_index] = -row.getCoeff(j)\n",
    "        elif constraint.Sense == GRB.LESS_EQUAL:\n",
    "            # keep <= constraints as they are\n",
    "            row = model.getRow(constraint)\n",
    "            for j in range(row.size()):\n",
    "                var = row.getVar(j)\n",
    "                col_index = var.index\n",
    "                A_matrix[i, col_index] = row.getCoeff(j)\n",
    "        else:\n",
    "            # raise an error if an equality constraint is encountered\n",
    "            raise ValueError(f\"Equality constraint found in constraint {constraint.ConstrName}. This is not allowed.\")\n",
    "    return A_matrix\n",
    "\n",
    "def getRhsVec(model):\n",
    "    num_constraints = model.NumConstrs\n",
    "    num_variables = model.NumVars\n",
    "    b_vector = np.zeros(num_constraints)\n",
    "    for i, constraint in enumerate(model.getConstrs()):\n",
    "        # check the sense and adjust if necessary\n",
    "        if constraint.Sense == GRB.GREATER_EQUAL:\n",
    "            b_vector[i] = -constraint.RHS\n",
    "        elif constraint.Sense == GRB.LESS_EQUAL:\n",
    "            # keep <= constraints as they are\n",
    "            b_vector[i] = constraint.RHS\n",
    "        else:\n",
    "            # raise an error if an equality constraint is encountered\n",
    "            raise ValueError(f\"Equality constraint found in constraint {constraint.ConstrName}. This is not allowed.\")\n",
    "    return b_vector\n",
    "\n",
    "def getBounds(model):\n",
    "    # lower bound\n",
    "    lb_vector = np.array([var.LB for var in model.getVars()])\n",
    "    # upper bound\n",
    "    ub_vector = np.array([var.UB for var in model.getVars()])\n",
    "    return lb_vector, ub_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fe4b0b-edf6-4214-bc8f-42d90f3809af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RHS vector for:\n",
      "[[-18.69   1.19 -11.95 ...   0.     0.     0.  ]\n",
      " [ -2.97  -3.11 -13.05 ...   0.     0.     0.  ]\n",
      " [ -3.29  -3.02 -13.03 ...   0.     0.     0.  ]\n",
      " ...\n",
      " [-17.73   0.93 -12.02 ...   0.     0.     0.  ]\n",
      " [-18.05   1.01 -11.99 ...   0.     0.     0.  ]\n",
      " [-18.37   1.1  -11.97 ...   0.     0.     0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# dir\n",
    "data_dir = r\".\\data\\datasets\\vary_rhs\\series_2\"\n",
    "# init data\n",
    "b_data = np.zeros((50, 1250))\n",
    "i = 0\n",
    "# go through files\n",
    "print(\"RHS vector for:\")\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith(\".mps.gz\"):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        # read file\n",
    "        with gzip.open(file_path, \"rb\") as f:\n",
    "            with open(\"temp.mps\", \"wb\") as temp_file:\n",
    "                temp_file.write(f.read())\n",
    "        # load model\n",
    "        model = gp.read(\"temp.mps\")\n",
    "        # print or process the RHS vector as needed\n",
    "        rhs_vector = getRhsVec(model)\n",
    "        b_data[i] = rhs_vector\n",
    "        # counting\n",
    "        i += 1\n",
    "print(b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e00640-07c8-4683-80cd-fef3a8e0ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(b_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5591259-03f1-486a-8c27-fc1047962201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var type\n",
    "types = getVarTypes(model)\n",
    "# objective\n",
    "c = getObjVec(model)\n",
    "# constraint\n",
    "A = getConstrMat(model)\n",
    "# bound\n",
    "lb, ub = getBounds(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee741ac2-8ba9-44fe-aae2-b37335cd8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 500 types: ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "The first 500 lower bounds are identical.\n",
      "Lower bound for first 500 variables: -inf\n",
      "The first 500 upper bounds are identical.\n",
      "Upper bound for first 500 variables: inf\n",
      "\n",
      "Last 500 types: ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "The last 500 lower bounds are identical.\n",
      "Lower bound for last 500 variables: 0.0\n",
      "The last 500 upper bounds are identical.\n",
      "Upper bound for last 500 variables: 1.0\n"
     ]
    }
   ],
   "source": [
    "# check if the first 500 variable types are identical\n",
    "print(\"First 500 types:\", types[:500])\n",
    "# check if the first 500 lower bounds are identical\n",
    "first_500_lb_consistent = np.all(lb[:500] == lb[0])\n",
    "if first_500_lb_consistent:\n",
    "    print(\"The first 500 lower bounds are identical.\")\n",
    "    print(\"Lower bound for first 500 variables:\", lb[0])\n",
    "else:\n",
    "    print(\"The first 500 lower bounds are not identical.\")\n",
    "    print(\"First 500 lower bounds:\", lb[:500])\n",
    "# check if the first 250 upper bounds are identical\n",
    "first_250_ub_consistent = np.all(ub[:500] == ub[0])\n",
    "if first_250_ub_consistent:\n",
    "    print(\"The first 500 upper bounds are identical.\")\n",
    "    print(\"Upper bound for first 500 variables:\", ub[0])\n",
    "else:\n",
    "    print(\"The first 500 upper bounds are not identical.\")\n",
    "    print(\"First 500 upper bounds:\", ub[:500])\n",
    "\n",
    "print()\n",
    "\n",
    "# check if the last 250 variable types are identical\n",
    "print(\"Last 500 types:\", types[-500:])\n",
    "# check if the last 250 lower bounds are identical\n",
    "last_500_lb_consistent = np.all(lb[-500:] == lb[-500])\n",
    "if last_500_lb_consistent:\n",
    "    print(\"The last 500 lower bounds are identical.\")\n",
    "    print(\"Lower bound for last 500 variables:\", lb[-500])\n",
    "else:\n",
    "    print(\"The last 500 lower bounds are not identical.\")\n",
    "    print(\"Last 500 lower bounds:\", lb[-500:])\n",
    "# check if the last 250 upper bounds are identical\n",
    "last_500_ub_consistent = np.all(ub[-500:] == ub[-500])\n",
    "if last_500_ub_consistent:\n",
    "    print(\"The last 500 upper bounds are identical.\")\n",
    "    print(\"Upper bound for last 500 variables:\", ub[-500])\n",
    "else:\n",
    "    print(\"The last 500 upper bounds are not identical.\")\n",
    "    print(\"Last 500 upper bounds:\", ub[-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd982f8a-bfe0-4bf3-83eb-5aa82033f58a",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6691f894-6590-4fb3-a5b3-815fbfb73b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values for each column in b_data: [-18.69  -3.11 -13.05 ...   0.     0.     0.  ]\n",
      "Maximum values for each column in b_data: [ -2.97   1.19 -11.95 ...   0.     0.     0.  ]\n"
     ]
    }
   ],
   "source": [
    "# find the maximum and minimum values for each column in b_data\n",
    "train_data_col_max = np.max(train_data, axis=0)\n",
    "train_data_col_min = np.min(train_data, axis=0)\n",
    "print(\"Minimum values for each column in b_data:\", train_data_col_min)\n",
    "print(\"Maximum values for each column in b_data:\", train_data_col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f9f46a-67c7-4169-a428-740695ff5b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of columns in b_data where all entries are non-zero:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218\n",
      " 219 220 221 222 223 224 225 226 227 228 229 230 231 233 234 235 236 237\n",
      " 238 239 240 241 242 243 244 245 246 247 248 249]\n"
     ]
    }
   ],
   "source": [
    "# identify columns with all non-zero elements in b_data\n",
    "non_zero_columns = np.all(train_data != 0, axis=0)\n",
    "non_zero_column_indices = np.where(non_zero_columns)[0]  # Get the indices of columns with all non-zero elements\n",
    "print(\"Indices of columns in b_data where all entries are non-zero:\")\n",
    "print(non_zero_column_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b785d280-ee95-4ead-be59-33959787f542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot histogram for the a column\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(train_data[:, 0], bins=20, edgecolor='black')\n",
    "plt.title(\"Distribution of First Column of training data\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85de1a6-e72e-4a0c-bc23-af94cf8476e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot histogram for the a column of b_data\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(train_data[:, 1], bins=20, edgecolor='black')\n",
    "plt.title(\"Distribution of Second Column of training data\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6bb32dc-a8d2-4837-a534-2acf186e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot histogram for the a column of\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(train_data[:, 99], bins=20, edgecolor='black')\n",
    "plt.title(\"Distribution of 100th Column of training data\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eece33-34e3-4a49-be55-533d4942307d",
   "metadata": {},
   "source": [
    "### Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c08e860-4804-41d3-8424-424394331ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled b_sample array:\n",
      "[[-1.26328180e+01  1.70428584e+00 -1.18040182e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.39943688e+01 -1.68941363e+00 -1.14465900e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-7.13125086e+00 -7.83421802e-01 -1.30714172e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [-9.46003224e+00 -2.02545317e+00 -1.12896774e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.20397859e+01  1.20947859e-02 -1.36297970e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.03376187e+01 -1.82784240e-01 -1.15633815e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# sample size\n",
    "sample_size = 8000\n",
    "# init sample\n",
    "train_sample = np.zeros((sample_size, train_data.shape[1]))\n",
    "# get the column-wise max and min values from train_data\n",
    "train_data_col_max = np.ceil(np.max(train_data, axis=0))[:250]\n",
    "train_data_col_min = np.floor(np.min(train_data, axis=0))[:250]\n",
    "# generate uniform random values for the first 250 rows between the min and max of each column\n",
    "train_sample[:, :250] = np.random.uniform(train_data_col_min, train_data_col_max, (sample_size, 250))\n",
    "# display the sampled b_sample array\n",
    "print(\"Sampled b_sample array:\")\n",
    "print(train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b33692-1fe3-4117-85cb-58c4f40340af",
   "metadata": {},
   "source": [
    "### Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e6be2f-2df1-48ed-bae2-e06b1db4962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setRHS(model, b):\n",
    "    # reset\n",
    "    model.reset() \n",
    "    # update the RHS values\n",
    "    for constr, new_rhs in zip(model.getConstrs(), b):\n",
    "        constr.RHS = new_rhs\n",
    "    # model update\n",
    "    model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e70f7b0-5c81-4771-88ef-26a4cf5444cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, x_val):\n",
    "    # check if the number of variables matches the input values\n",
    "    vars_in_model = model.getVars()\n",
    "    if len(vars_in_model) != len(x_val):\n",
    "        raise ValueError(\"The length of x_val does not match the number of model variables!\")\n",
    "    # calculate the objective function value\n",
    "    objval = sum(var.Obj * val for var, val in zip(vars_in_model, x_val))\n",
    "    # calculate constraint violations\n",
    "    viols = []\n",
    "    for constr in model.getConstrs():\n",
    "        # Compute the left-hand side (lhs) value of the constraint\n",
    "        lhs = sum(val * model.getCoeff(constr, var) for var, val in zip(vars_in_model, x_val))\n",
    "        rhs = constr.rhs\n",
    "        # determine the violation amount based on the constraint sense\n",
    "        violation = max(0, lhs - rhs - 1e-6) if constr.sense == GRB.LESS_EQUAL else \\\n",
    "                    max(0, rhs - lhs - 1e-6) if constr.sense == GRB.GREATER_EQUAL else \\\n",
    "                    abs(lhs - rhs)\n",
    "        # record the constraint name and its violation amount\n",
    "        viols.append(violation)\n",
    "    return objval, np.array(viols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacab8c6-603a-4d87-9b7b-7192a12548ac",
   "metadata": {},
   "source": [
    "#### Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1bd69fa-e0c6-44d6-aadc-be9c90a97988",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3f8cc3-7f4f-4a5f-8c86-3da5b23759a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:52<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Mean Violation  Max Violation  Num Violations  \\\n",
      "count     10.000000            10.0           10.0            10.0   \n",
      "mean  -17169.485687             0.0            0.0             0.0   \n",
      "std        1.269903             0.0            0.0             0.0   \n",
      "min   -17171.525260             0.0            0.0             0.0   \n",
      "25%   -17170.355450             0.0            0.0             0.0   \n",
      "50%   -17169.264223             0.0            0.0             0.0   \n",
      "75%   -17168.411405             0.0            0.0             0.0   \n",
      "max   -17167.980247             0.0            0.0             0.0   \n",
      "\n",
      "       Elapsed Time  \n",
      "count     10.000000  \n",
      "mean       3.835735  \n",
      "std        0.385178  \n",
      "min        3.263200  \n",
      "25%        3.540173  \n",
      "50%        3.820655  \n",
      "75%        4.074691  \n",
      "max        4.495883  \n",
      "Total elapsed time for optimization: 38.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = gp.read(\"temp.mps\")\n",
    "# init df\n",
    "params, sols, objvals, mean_viols, max_viols, num_viols, elapseds = [], [], [], [], [], [], []\n",
    "for b in tqdm(test_data):\n",
    "    # set rhs\n",
    "    setRHS(model, b)\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    model.optimize()\n",
    "    tock = time.time()\n",
    "    # get solutions\n",
    "    x_val = [var.x for var in model.getVars()]\n",
    "    obj, viol = evaluateModel(model, x_val)\n",
    "    # record\n",
    "    params.append(list(b[:250]))\n",
    "    sols.append(x_val)\n",
    "    objvals.append(obj)\n",
    "    mean_viols.append(np.mean(viol))\n",
    "    max_viols.append(np.max(viol))\n",
    "    num_viols.append(np.sum(viol > 1e-6))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\": params,\n",
    "                   \"Sol\": sols,\n",
    "                   \"Obj Val\": objvals,\n",
    "                   \"Mean Violation\": mean_viols,\n",
    "                   \"Max Violation\": max_viols,\n",
    "                   \"Num Violations\": num_viols,\n",
    "                   \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Total elapsed time for optimization: {:.2f} seconds\".format(df[\"Elapsed Time\"].sum()))\n",
    "df.to_csv(\"result/lp_exact_rhs-series2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482fed4-0ad2-4778-b8b8-87ec9e504876",
   "metadata": {},
   "source": [
    "#### N1 Hueristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "234f09a5-e54b-4df4-99e0-ddd46c79a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "713f93be-6dc6-45e7-84a9-4e9618be57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:15<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Mean Violation  Max Violation  Num Violations  \\\n",
      "count    10.000000            10.0           10.0            10.0   \n",
      "mean  -7409.652066             0.0            0.0             0.0   \n",
      "std       0.084518             0.0            0.0             0.0   \n",
      "min   -7409.778049             0.0            0.0             0.0   \n",
      "25%   -7409.713027             0.0            0.0             0.0   \n",
      "50%   -7409.647334             0.0            0.0             0.0   \n",
      "75%   -7409.586088             0.0            0.0             0.0   \n",
      "max   -7409.530987             0.0            0.0             0.0   \n",
      "\n",
      "       Elapsed Time  \n",
      "count     10.000000  \n",
      "mean       0.219877  \n",
      "std        0.014790  \n",
      "min        0.204592  \n",
      "25%        0.206350  \n",
      "50%        0.221247  \n",
      "75%        0.227012  \n",
      "max        0.251482  \n",
      "Total elapsed time for optimization: 2.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = gp.read(\"temp.mps\")\n",
    "# limit to root node\n",
    "model.setParam(\"SolutionLimit\", 1) \n",
    "# init df\n",
    "params, sols, objvals, mean_viols, max_viols, num_viols, elapseds = [], [], [], [], [], [], []\n",
    "for b in tqdm(test_data):\n",
    "    # set rhs\n",
    "    setRHS(model, b)\n",
    "    # solve\n",
    "    tick = time.time()\n",
    "    model.optimize()\n",
    "    tock = time.time()\n",
    "    # get solutions\n",
    "    x_val = [var.x for var in model.getVars()]\n",
    "    obj, viol = evaluateModel(model, x_val)\n",
    "    # record\n",
    "    params.append(list(b[:250]))\n",
    "    sols.append(x_val)\n",
    "    objvals.append(obj)\n",
    "    mean_viols.append(np.mean(viol))\n",
    "    max_viols.append(np.max(viol))\n",
    "    num_viols.append(np.sum(viol > 1e-6))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\": params,\n",
    "                   \"Sol\": sols,\n",
    "                   \"Obj Val\": objvals,\n",
    "                   \"Mean Violation\": mean_viols,\n",
    "                   \"Max Violation\": max_viols,\n",
    "                   \"Num Violations\": num_viols,\n",
    "                   \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Total elapsed time for optimization: {:.2f} seconds\".format(df[\"Elapsed Time\"].sum()))\n",
    "df.to_csv(\"result/lp_root_rhs-series2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef84ca8-6b5b-4b73-beeb-888d05d37f05",
   "metadata": {},
   "source": [
    "### Learning-to-Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c474cff-64a9-44a9-ae06-b114b3cc89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hpyerparameters\n",
    "batch_size = 64\n",
    "hlayers_sol = 5\n",
    "hlayers_rnd = 4\n",
    "hsize = 256\n",
    "lr = 1e-3\n",
    "penalty_weight = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac85f1a2-0a29-4d86-9cae-b872ad76dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from neuromancer.dataset import DictDataset\n",
    "# get dataset\n",
    "data_train = DictDataset({\"b\":torch.from_numpy(train_sample[:,:250]).float()}, name=\"train\")\n",
    "data_val = DictDataset({\"b\":torch.from_numpy(train_data[:,:250]).float()}, name=\"train\")\n",
    "# set dataloader\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0,\n",
    "                          collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_val   = DataLoader(data_val, batch_size, num_workers=0,\n",
    "                          collate_fn=data_train.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5780be-00ed-4376-85bc-875f3561ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class penaltyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Penalty loss function for linear optimization problems.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_keys, A, c, lb, ub, penalty_weight=50, output_key=\"loss\"):\n",
    "        \"\"\"\n",
    "        Initialize penalty loss with problem parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.b_key, self.x_key = input_keys\n",
    "        self.output_key = output_key\n",
    "        self.penalty_weight = penalty_weight\n",
    "        self.device = None\n",
    "        # fixed coefficients\n",
    "        self.A = torch.from_numpy(A).float()\n",
    "        self.c = torch.from_numpy(c).float()\n",
    "        self.lb = torch.from_numpy(lb).float()\n",
    "        self.ub = torch.from_numpy(ub).float()\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        \"\"\"\n",
    "        Forward pass to compute the penalty loss.\n",
    "        \"\"\"\n",
    "        # objective function calculation\n",
    "        obj_value = self.cal_obj(input_dict)\n",
    "        # constraint violation calculation\n",
    "        viol_value = self.cal_constr_viol(input_dict)\n",
    "        # penalized loss\n",
    "        loss = obj_value + self.penalty_weight * viol_value\n",
    "        # mean loss\n",
    "        input_dict[self.output_key] = torch.mean(loss)\n",
    "        return input_dict\n",
    "\n",
    "    def cal_obj(self, input_dict):\n",
    "        \"\"\"\n",
    "        Calculate the linear objective function.\n",
    "        \"\"\"\n",
    "        x = input_dict[self.x_key]\n",
    "        # move parameters to the correct device if not already set\n",
    "        if self.device is None:\n",
    "            self.device = x.device\n",
    "            self.c = self.c.to(self.device)\n",
    "            self.A = self.A.to(self.device)\n",
    "            self.lb = self.lb.to(self.device)\n",
    "            self.ub = self.ub.to(self.device)\n",
    "        # calculate c^T x for the objective\n",
    "        obj_term = torch.einsum(\"n,bn->b\", self.c, x)\n",
    "        return obj_term\n",
    "\n",
    "    def cal_constr_viol(self, input_dict):\n",
    "        \"\"\"\n",
    "        Calculate constraint and bounds violations.\n",
    "        \"\"\"\n",
    "        x, b = input_dict[self.x_key], input_dict[self.b_key]\n",
    "        # fill 0 for rhs\n",
    "        b = torch.cat([b, torch.zeros(b.shape[0], self.A.shape[0] - b.shape[1], device=b.device)], dim=1)\n",
    "        # calculate constraint violations (Ax <= b)\n",
    "        lhs = torch.einsum(\"mn,bn->bm\", self.A, x)  # Ax\n",
    "        constr_violation = (torch.relu(lhs - b) ** 2).sum(dim=1)  # Max(0, Ax - b)\n",
    "        # calculate bounds violations\n",
    "        lower_violation = (torch.relu(self.lb - x) ** 2).sum(dim=1)  # x >= lb\n",
    "        upper_violation = (torch.relu(x - self.ub) ** 2).sum(dim=1)  # x <= ub\n",
    "        return constr_violation + lower_violation + upper_violation\n",
    "\n",
    "    def get_constr_viol(self, input_dict):\n",
    "        \"\"\"\n",
    "        Calculate constraint and bounds violations.\n",
    "        \"\"\"\n",
    "        x, b = input_dict[self.x_key], input_dict[self.b_key]\n",
    "        # fill 0 for rhs\n",
    "        b = torch.cat([b, torch.zeros(b.shape[0], self.A.shape[0] - b.shape[1], device=b.device)], dim=1)\n",
    "        # calculate constraint violations (Ax <= b)\n",
    "        lhs = torch.einsum(\"mn,bn->bm\", self.A, x)  # Ax\n",
    "        constr_violation = torch.relu(lhs - b - 1e-5).max(dim=1)[0]  # Max(0, Ax - b)\n",
    "        # calculate bounds violations\n",
    "        lower_violation = torch.relu(self.lb - x - 1e-5).max(dim=1)[0]  # x >= lb\n",
    "        upper_violation = torch.relu(x - self.ub - 1e-5).max(dim=1)[0]  # x <= ub\n",
    "        return torch.stack([constr_violation, lower_violation, upper_violation], dim=1).max(dim=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c0228-fe20-4121-a016-94270d3c79c5",
   "metadata": {},
   "source": [
    "#### Rounding Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7fef6da-65b1-47f0-89e3-58ada5bae053",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afad3c94-a80b-47d9-a512-7a42aa4c3401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuromancer as nm\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=250, outsize=model.NumVars, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=250+model.NumVars,\n",
    "                   hidden_dims=[hsize]*hlayers_rnd,\n",
    "                   output_dim=model.NumVars)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],\n",
    "                       output_keys=[\"x_rnd\"], bin_ind={\"x\":range(500,1000)},\n",
    "                       continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = penaltyLoss([\"b\", \"x_rnd\"], A, c, lb, ub, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61691c38-60fb-4b68-a9e3-d4541bf64938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 601133504.00\n",
      "Epoch 0, Iters 125, Training Loss: 765880262.72, Validation Loss: 459677280.00\n",
      "Epoch 1, Iters 250, Training Loss: 35467804.13, Validation Loss: 10977016.00\n",
      "Epoch 2, Iters 375, Training Loss: 13914638.14, Validation Loss: 4032806.00\n",
      "Epoch 3, Iters 500, Training Loss: 6884971.59, Validation Loss: 2193938.50\n",
      "Epoch 4, Iters 625, Training Loss: 3403062.27, Validation Loss: 2018924.25\n",
      "Epoch 5, Iters 750, Training Loss: 2092954.60, Validation Loss: 1767392.38\n",
      "Epoch 6, Iters 875, Training Loss: 1111516.65, Validation Loss: 625535.62\n",
      "Epoch 7, Iters 1000, Training Loss: 664809.57, Validation Loss: 208734.88\n",
      "Epoch 8, Iters 1125, Training Loss: 528335.23, Validation Loss: 294537.50\n",
      "Epoch 9, Iters 1250, Training Loss: 357676.08, Validation Loss: 315782.56\n",
      "Epoch 10, Iters 1375, Training Loss: 261707.29, Validation Loss: 71870.74\n",
      "Epoch 11, Iters 1500, Training Loss: 256459.24, Validation Loss: 55716.90\n",
      "Epoch 12, Iters 1625, Training Loss: 125272.24, Validation Loss: 27929.72\n",
      "Epoch 13, Iters 1750, Training Loss: 106513.87, Validation Loss: 27908.08\n",
      "Epoch 14, Iters 1875, Training Loss: 118101.93, Validation Loss: 9947.09\n",
      "Epoch 15, Iters 2000, Training Loss: 91104.37, Validation Loss: 19959.61\n",
      "Epoch 16, Iters 2125, Training Loss: 74487.51, Validation Loss: 26292.69\n",
      "Epoch 17, Iters 2250, Training Loss: 78112.44, Validation Loss: 34887.79\n",
      "Epoch 18, Iters 2375, Training Loss: 66268.45, Validation Loss: 651.07\n",
      "Epoch 19, Iters 2500, Training Loss: 20962.35, Validation Loss: -2418.99\n",
      "Epoch 20, Iters 2625, Training Loss: 32492.83, Validation Loss: -491.40\n",
      "Epoch 21, Iters 2750, Training Loss: 28537.80, Validation Loss: -2182.73\n",
      "Epoch 22, Iters 2875, Training Loss: 30085.81, Validation Loss: -2119.14\n",
      "Epoch 23, Iters 3000, Training Loss: 7988.26, Validation Loss: -2582.52\n",
      "Epoch 24, Iters 3125, Training Loss: 37397.05, Validation Loss: -3794.51\n",
      "Epoch 25, Iters 3250, Training Loss: 12235.52, Validation Loss: -3866.79\n",
      "Epoch 26, Iters 3375, Training Loss: 17173.61, Validation Loss: -4768.63\n",
      "Epoch 27, Iters 3500, Training Loss: 17629.38, Validation Loss: -4995.45\n",
      "Epoch 28, Iters 3625, Training Loss: 17100.36, Validation Loss: -5575.29\n",
      "Epoch 29, Iters 3750, Training Loss: 8284.38, Validation Loss: -783.44\n",
      "Epoch 30, Iters 3875, Training Loss: 9868.26, Validation Loss: -5934.77\n",
      "Epoch 31, Iters 4000, Training Loss: 10199.64, Validation Loss: -6107.22\n",
      "Epoch 32, Iters 4125, Training Loss: 9974.62, Validation Loss: -3753.77\n",
      "Epoch 33, Iters 4250, Training Loss: 5696.51, Validation Loss: 319.75\n",
      "Epoch 34, Iters 4375, Training Loss: 10311.45, Validation Loss: -6074.19\n",
      "Epoch 35, Iters 4500, Training Loss: 3749.08, Validation Loss: -6705.25\n",
      "Epoch 36, Iters 4625, Training Loss: 9921.40, Validation Loss: -6506.18\n",
      "Epoch 37, Iters 4750, Training Loss: 5921.54, Validation Loss: -7540.55\n",
      "Epoch 38, Iters 4875, Training Loss: 6287.44, Validation Loss: -7876.66\n",
      "Epoch 39, Iters 5000, Training Loss: 11138.06, Validation Loss: -7087.69\n",
      "Epoch 40, Iters 5125, Training Loss: 10408.28, Validation Loss: -6488.49\n",
      "Epoch 41, Iters 5250, Training Loss: 7733.30, Validation Loss: -6748.15\n",
      "Epoch 42, Iters 5375, Training Loss: -503.70, Validation Loss: -7804.06\n",
      "Epoch 43, Iters 5500, Training Loss: 833.21, Validation Loss: -7152.48\n",
      "Epoch 44, Iters 5625, Training Loss: 8031.04, Validation Loss: -8234.15\n",
      "Epoch 45, Iters 5750, Training Loss: 2296.22, Validation Loss: -8423.05\n",
      "Epoch 46, Iters 5875, Training Loss: 8195.84, Validation Loss: -8101.39\n",
      "Epoch 47, Iters 6000, Training Loss: 2260.81, Validation Loss: -7800.02\n",
      "Epoch 48, Iters 6125, Training Loss: 6863.11, Validation Loss: -9054.56\n",
      "Epoch 49, Iters 6250, Training Loss: 6891.47, Validation Loss: -8898.70\n",
      "Epoch 50, Iters 6375, Training Loss: 4905.25, Validation Loss: -8935.95\n",
      "Epoch 51, Iters 6500, Training Loss: 6407.04, Validation Loss: -8721.35\n",
      "Epoch 52, Iters 6625, Training Loss: 1860.76, Validation Loss: -8736.60\n",
      "Epoch 53, Iters 6750, Training Loss: 4108.22, Validation Loss: -8468.86\n",
      "Epoch 54, Iters 6875, Training Loss: -2229.61, Validation Loss: -6928.47\n",
      "Epoch 55, Iters 7000, Training Loss: 8371.84, Validation Loss: -9387.45\n",
      "Epoch 56, Iters 7125, Training Loss: -1376.76, Validation Loss: -8425.75\n",
      "Epoch 57, Iters 7250, Training Loss: 2198.10, Validation Loss: -7332.25\n",
      "Epoch 58, Iters 7375, Training Loss: 3654.11, Validation Loss: -8727.08\n",
      "Epoch 59, Iters 7500, Training Loss: 1616.65, Validation Loss: -8999.07\n",
      "Epoch 60, Iters 7625, Training Loss: 771.27, Validation Loss: -9587.30\n",
      "Epoch 61, Iters 7750, Training Loss: -112.96, Validation Loss: -9005.17\n",
      "Epoch 62, Iters 7875, Training Loss: 5755.27, Validation Loss: -9414.66\n",
      "Epoch 63, Iters 8000, Training Loss: 1902.09, Validation Loss: -9564.85\n",
      "Epoch 64, Iters 8125, Training Loss: 3221.59, Validation Loss: -9576.89\n",
      "Epoch 65, Iters 8250, Training Loss: 595.68, Validation Loss: -9031.63\n",
      "Epoch 66, Iters 8375, Training Loss: -2761.19, Validation Loss: -8765.46\n",
      "Epoch 67, Iters 8500, Training Loss: 1727.05, Validation Loss: -9581.23\n",
      "Epoch 68, Iters 8625, Training Loss: -6171.70, Validation Loss: -9488.18\n",
      "Epoch 69, Iters 8750, Training Loss: 28.93, Validation Loss: -8570.50\n",
      "Epoch 70, Iters 8875, Training Loss: -2116.33, Validation Loss: -4474.67\n",
      "Epoch 71, Iters 9000, Training Loss: -3052.17, Validation Loss: -10054.77\n",
      "Epoch 72, Iters 9125, Training Loss: -481.55, Validation Loss: -8854.06\n",
      "Epoch 73, Iters 9250, Training Loss: -1990.20, Validation Loss: -9673.73\n",
      "Epoch 74, Iters 9375, Training Loss: -805.48, Validation Loss: -10011.11\n",
      "Epoch 75, Iters 9500, Training Loss: -507.17, Validation Loss: -9660.91\n",
      "Epoch 76, Iters 9625, Training Loss: 3333.02, Validation Loss: -7846.62\n",
      "Epoch 77, Iters 9750, Training Loss: 56.61, Validation Loss: -9026.77\n",
      "Epoch 78, Iters 9875, Training Loss: -4238.89, Validation Loss: -9584.23\n",
      "Epoch 79, Iters 10000, Training Loss: -1699.09, Validation Loss: -9946.02\n",
      "Epoch 80, Iters 10125, Training Loss: -3267.51, Validation Loss: -7096.56\n",
      "Epoch 81, Iters 10250, Training Loss: -2622.76, Validation Loss: -10008.83\n",
      "Epoch 82, Iters 10375, Training Loss: -552.14, Validation Loss: -9305.22\n",
      "Epoch 83, Iters 10500, Training Loss: -4034.25, Validation Loss: -8006.75\n",
      "Epoch 84, Iters 10625, Training Loss: 3121.22, Validation Loss: -9220.92\n",
      "Epoch 85, Iters 10750, Training Loss: -1541.41, Validation Loss: -8388.99\n",
      "Epoch 86, Iters 10875, Training Loss: -4080.34, Validation Loss: -9845.87\n",
      "Epoch 87, Iters 11000, Training Loss: 153.61, Validation Loss: -5508.57\n",
      "Epoch 88, Iters 11125, Training Loss: 241.00, Validation Loss: -9821.16\n",
      "Epoch 89, Iters 11250, Training Loss: -3176.09, Validation Loss: -9621.92\n",
      "Epoch 90, Iters 11375, Training Loss: -887.45, Validation Loss: -10346.33\n",
      "Epoch 91, Iters 11500, Training Loss: 2147.25, Validation Loss: -6454.09\n",
      "Epoch 92, Iters 11625, Training Loss: -6567.84, Validation Loss: -10100.58\n",
      "Epoch 93, Iters 11750, Training Loss: -2814.33, Validation Loss: -10013.75\n",
      "Epoch 94, Iters 11875, Training Loss: -3036.23, Validation Loss: -10079.32\n",
      "Epoch 95, Iters 12000, Training Loss: 1563.78, Validation Loss: -9396.99\n",
      "Epoch 96, Iters 12125, Training Loss: 993.57, Validation Loss: -9978.50\n",
      "Epoch 97, Iters 12250, Training Loss: -550.58, Validation Loss: -10004.17\n",
      "Epoch 98, Iters 12375, Training Loss: -2052.19, Validation Loss: -10115.50\n",
      "Epoch 99, Iters 12500, Training Loss: -3763.52, Validation Loss: -10348.16\n",
      "Epoch 100, Iters 12625, Training Loss: 2229.35, Validation Loss: -9477.07\n",
      "Epoch 101, Iters 12750, Training Loss: -4611.18, Validation Loss: -9925.30\n",
      "Epoch 102, Iters 12875, Training Loss: -4929.43, Validation Loss: -10530.94\n",
      "Epoch 103, Iters 13000, Training Loss: -3063.16, Validation Loss: -10570.83\n",
      "Epoch 104, Iters 13125, Training Loss: -1456.53, Validation Loss: -10190.15\n",
      "Epoch 105, Iters 13250, Training Loss: -6301.34, Validation Loss: -10362.37\n",
      "Epoch 106, Iters 13375, Training Loss: -2945.40, Validation Loss: -10274.19\n",
      "Epoch 107, Iters 13500, Training Loss: -2523.35, Validation Loss: -10421.62\n",
      "Epoch 108, Iters 13625, Training Loss: -4101.30, Validation Loss: -10221.39\n",
      "Epoch 109, Iters 13750, Training Loss: -2293.27, Validation Loss: -10080.44\n",
      "Epoch 110, Iters 13875, Training Loss: -2850.35, Validation Loss: -10167.66\n",
      "Epoch 111, Iters 14000, Training Loss: -3654.98, Validation Loss: -10131.21\n",
      "Epoch 112, Iters 14125, Training Loss: -6417.84, Validation Loss: -9845.84\n",
      "Epoch 113, Iters 14250, Training Loss: -6243.49, Validation Loss: -10385.82\n",
      "Epoch 114, Iters 14375, Training Loss: -7253.29, Validation Loss: -10499.13\n",
      "Epoch 115, Iters 14500, Training Loss: 853.32, Validation Loss: -10330.70\n",
      "Epoch 116, Iters 14625, Training Loss: -2845.96, Validation Loss: -10176.28\n",
      "Epoch 117, Iters 14750, Training Loss: -3395.52, Validation Loss: -10212.14\n",
      "Epoch 118, Iters 14875, Training Loss: -3353.78, Validation Loss: -10143.58\n",
      "Epoch 119, Iters 15000, Training Loss: -5567.27, Validation Loss: -10394.14\n",
      "Epoch 120, Iters 15125, Training Loss: -3294.80, Validation Loss: -9942.83\n",
      "Epoch 121, Iters 15250, Training Loss: -4312.84, Validation Loss: -9300.04\n",
      "Epoch 122, Iters 15375, Training Loss: -5937.74, Validation Loss: -10214.20\n",
      "Epoch 123, Iters 15500, Training Loss: -3262.50, Validation Loss: -10829.63\n",
      "Epoch 124, Iters 15625, Training Loss: -1087.55, Validation Loss: -9859.59\n",
      "Epoch 125, Iters 15750, Training Loss: -6017.26, Validation Loss: -10879.74\n",
      "Epoch 126, Iters 15875, Training Loss: -3110.50, Validation Loss: -10583.97\n",
      "Epoch 127, Iters 16000, Training Loss: -554.84, Validation Loss: -10239.07\n",
      "Epoch 128, Iters 16125, Training Loss: -6346.42, Validation Loss: -10212.67\n",
      "Epoch 129, Iters 16250, Training Loss: -4251.18, Validation Loss: -10207.00\n",
      "Epoch 130, Iters 16375, Training Loss: -5133.24, Validation Loss: -10978.63\n",
      "Epoch 131, Iters 16500, Training Loss: -4169.45, Validation Loss: -10524.58\n",
      "Epoch 132, Iters 16625, Training Loss: -3500.60, Validation Loss: -8951.06\n",
      "Epoch 133, Iters 16750, Training Loss: -2640.09, Validation Loss: -10191.22\n",
      "Epoch 134, Iters 16875, Training Loss: -4125.30, Validation Loss: -10759.34\n",
      "Epoch 135, Iters 17000, Training Loss: -3870.04, Validation Loss: -10605.55\n",
      "Epoch 136, Iters 17125, Training Loss: -3562.83, Validation Loss: -10116.84\n",
      "Epoch 137, Iters 17250, Training Loss: -2730.49, Validation Loss: -9430.11\n",
      "Epoch 138, Iters 17375, Training Loss: -4582.53, Validation Loss: -10797.19\n",
      "Epoch 139, Iters 17500, Training Loss: -3579.89, Validation Loss: -10677.82\n",
      "Epoch 140, Iters 17625, Training Loss: -3141.39, Validation Loss: -10921.31\n",
      "Epoch 141, Iters 17750, Training Loss: -4354.98, Validation Loss: -10831.68\n",
      "Epoch 142, Iters 17875, Training Loss: -4532.13, Validation Loss: -10893.80\n",
      "Epoch 143, Iters 18000, Training Loss: -5609.17, Validation Loss: -10853.88\n",
      "Epoch 144, Iters 18125, Training Loss: -1200.73, Validation Loss: -10617.13\n",
      "Epoch 145, Iters 18250, Training Loss: 520.13, Validation Loss: -9123.12\n",
      "Epoch 146, Iters 18375, Training Loss: -6274.75, Validation Loss: -10212.75\n",
      "Epoch 147, Iters 18500, Training Loss: -3183.64, Validation Loss: -10522.79\n",
      "Epoch 148, Iters 18625, Training Loss: -6033.56, Validation Loss: -10613.11\n",
      "Epoch 149, Iters 18750, Training Loss: -1107.98, Validation Loss: -10788.80\n",
      "Epoch 150, Iters 18875, Training Loss: -4771.16, Validation Loss: -10657.36\n",
      "Epoch 151, Iters 19000, Training Loss: -5830.85, Validation Loss: -9995.50\n",
      "Epoch 152, Iters 19125, Training Loss: -2657.59, Validation Loss: -10648.12\n",
      "Epoch 153, Iters 19250, Training Loss: -5344.14, Validation Loss: -9129.78\n",
      "Epoch 154, Iters 19375, Training Loss: -2704.22, Validation Loss: -10804.84\n",
      "Epoch 155, Iters 19500, Training Loss: -5355.16, Validation Loss: -10634.39\n",
      "Epoch 156, Iters 19625, Training Loss: -4170.74, Validation Loss: -8757.08\n",
      "Epoch 157, Iters 19750, Training Loss: -3448.83, Validation Loss: -11039.51\n",
      "Epoch 158, Iters 19875, Training Loss: -2531.26, Validation Loss: -9931.44\n",
      "Epoch 159, Iters 20000, Training Loss: -5721.06, Validation Loss: -10578.63\n",
      "Epoch 160, Iters 20125, Training Loss: -4037.04, Validation Loss: -10618.75\n",
      "Epoch 161, Iters 20250, Training Loss: -6613.16, Validation Loss: -10529.26\n",
      "Epoch 162, Iters 20375, Training Loss: -5962.80, Validation Loss: -10963.71\n",
      "Epoch 163, Iters 20500, Training Loss: -599.67, Validation Loss: -9843.44\n",
      "Epoch 164, Iters 20625, Training Loss: -4257.48, Validation Loss: -11098.19\n",
      "Epoch 165, Iters 20750, Training Loss: -7298.38, Validation Loss: -11470.19\n",
      "Epoch 166, Iters 20875, Training Loss: -5105.41, Validation Loss: -10725.43\n",
      "Epoch 167, Iters 21000, Training Loss: -4970.98, Validation Loss: -11319.71\n",
      "Epoch 168, Iters 21125, Training Loss: -3951.27, Validation Loss: -10302.78\n",
      "Epoch 169, Iters 21250, Training Loss: -3551.22, Validation Loss: -10584.42\n",
      "Epoch 170, Iters 21375, Training Loss: -4873.60, Validation Loss: -10296.17\n",
      "Epoch 171, Iters 21500, Training Loss: -5009.37, Validation Loss: -11141.58\n",
      "Epoch 172, Iters 21625, Training Loss: -2403.20, Validation Loss: -11117.64\n",
      "Epoch 173, Iters 21750, Training Loss: -1891.98, Validation Loss: -10643.74\n",
      "Epoch 174, Iters 21875, Training Loss: -2359.04, Validation Loss: -10910.82\n",
      "Epoch 175, Iters 22000, Training Loss: -7030.66, Validation Loss: -11109.92\n",
      "Epoch 176, Iters 22125, Training Loss: -6157.24, Validation Loss: -10593.83\n",
      "Epoch 177, Iters 22250, Training Loss: -5047.23, Validation Loss: -10829.83\n",
      "Epoch 178, Iters 22375, Training Loss: -4815.99, Validation Loss: -8994.39\n",
      "Epoch 179, Iters 22500, Training Loss: -5602.43, Validation Loss: -11055.67\n",
      "Epoch 180, Iters 22625, Training Loss: -6930.44, Validation Loss: -10717.76\n",
      "Epoch 181, Iters 22750, Training Loss: -4893.19, Validation Loss: -11056.15\n",
      "Epoch 182, Iters 22875, Training Loss: -4718.10, Validation Loss: -10736.83\n",
      "Epoch 183, Iters 23000, Training Loss: -5782.89, Validation Loss: -11200.66\n",
      "Epoch 184, Iters 23125, Training Loss: -4103.83, Validation Loss: -10058.58\n",
      "Epoch 185, Iters 23250, Training Loss: -5923.47, Validation Loss: -11022.90\n",
      "Epoch 186, Iters 23375, Training Loss: -3911.76, Validation Loss: -10695.34\n",
      "Epoch 187, Iters 23500, Training Loss: -3054.47, Validation Loss: -11109.47\n",
      "Epoch 188, Iters 23625, Training Loss: -3336.63, Validation Loss: -10313.50\n",
      "Epoch 189, Iters 23750, Training Loss: -4272.61, Validation Loss: -11178.84\n",
      "Epoch 190, Iters 23875, Training Loss: -7502.94, Validation Loss: -10785.63\n",
      "Epoch 191, Iters 24000, Training Loss: -6476.27, Validation Loss: -10667.31\n",
      "Epoch 192, Iters 24125, Training Loss: -5371.42, Validation Loss: -11174.97\n",
      "Epoch 193, Iters 24250, Training Loss: -4369.36, Validation Loss: -10697.92\n",
      "Epoch 194, Iters 24375, Training Loss: -5291.70, Validation Loss: -10843.59\n",
      "Epoch 195, Iters 24500, Training Loss: -6124.18, Validation Loss: -10223.08\n",
      "Epoch 196, Iters 24625, Training Loss: -6152.49, Validation Loss: -10966.43\n",
      "Epoch 197, Iters 24750, Training Loss: -4920.42, Validation Loss: -10686.80\n",
      "Epoch 198, Iters 24875, Training Loss: -5990.37, Validation Loss: -10513.12\n",
      "Epoch 199, Iters 25000, Training Loss: -5847.54, Validation Loss: -11010.07\n",
      "Epoch 200, Iters 25125, Training Loss: -3865.93, Validation Loss: -11218.43\n",
      "Epoch 201, Iters 25250, Training Loss: -5909.77, Validation Loss: -10972.35\n",
      "Epoch 202, Iters 25375, Training Loss: -5697.59, Validation Loss: -11134.58\n",
      "Epoch 203, Iters 25500, Training Loss: -5217.12, Validation Loss: -11271.94\n",
      "Epoch 204, Iters 25625, Training Loss: -2863.04, Validation Loss: -11198.89\n",
      "Epoch 205, Iters 25750, Training Loss: -2530.83, Validation Loss: -11178.18\n",
      "Early stopping at iters 25750\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 409.02 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 400                    # number of training epochs\n",
    "warmup = 40                    # number of epochs to wait before enacting early stopping policy\n",
    "patience = 40                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e45e0270-e288-4511-84c5-b5be97c3c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:47<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Obj Val  Mean Violation  Max Violation  Num Violations  \\\n",
      "count     10.000000       10.000000      10.000000       10.000000   \n",
      "mean  -11532.254466        0.000352       0.031569       73.800000   \n",
      "std       42.063517        0.000003       0.000113        0.632456   \n",
      "min   -11591.656721        0.000348       0.031417       73.000000   \n",
      "25%   -11566.397810        0.000349       0.031483       73.250000   \n",
      "50%   -11527.955133        0.000351       0.031550       74.000000   \n",
      "75%   -11497.779313        0.000354       0.031670       74.000000   \n",
      "max   -11476.012021        0.000356       0.031731       75.000000   \n",
      "\n",
      "       Elapsed Time  \n",
      "count     10.000000  \n",
      "mean       0.004413  \n",
      "std        0.000831  \n",
      "min        0.003119  \n",
      "25%        0.004008  \n",
      "50%        0.004219  \n",
      "75%        0.004927  \n",
      "max        0.005677  \n",
      "Total elapsed time for optimization: 0.04 seconds\n",
      "Number of infeasible solution: 10\n"
     ]
    }
   ],
   "source": [
    "# init df\n",
    "params, sols, objvals, mean_viols, max_viols, num_viols, elapseds = [], [], [], [], [], [], []\n",
    "for b in tqdm(test_data):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(torch.tensor(b).float()[:250], 0).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # get solutions\n",
    "    x_val = datapoints[\"x_rnd\"][0].detach().cpu().numpy()\n",
    "    obj, viol = evaluateModel(model, x_val)\n",
    "    # record\n",
    "    params.append(list(b[:250]))\n",
    "    sols.append(x_val)\n",
    "    objvals.append(obj)\n",
    "    mean_viols.append(np.mean(viol))\n",
    "    max_viols.append(np.max(viol))\n",
    "    num_viols.append(np.sum(viol > 1e-6))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\": params,\n",
    "                   \"Sol\": sols,\n",
    "                   \"Obj Val\": objvals,\n",
    "                   \"Mean Violation\": mean_viols,\n",
    "                   \"Max Violation\": max_viols,\n",
    "                   \"Num Violations\": num_viols,\n",
    "                   \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Total elapsed time for optimization: {:.2f} seconds\".format(df[\"Elapsed Time\"].sum()))\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Num Violations\"] > 0)))\n",
    "df.to_csv(\"result/lp_cls_rhs-series2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c518f-4f8e-424b-bfd2-f179719aa0b0",
   "metadata": {},
   "source": [
    "#### Learnable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb5e2b4f-5001-4379-97f9-174a67b635f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29326d5-a8fb-4134-9c84-a57f771b3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuromancer as nm\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundThresholdModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=250, outsize=model.NumVars, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"b\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=250+model.NumVars,\n",
    "                   hidden_dims=[hsize]*hlayers_rnd,\n",
    "                   output_dim=model.NumVars)\n",
    "rnd = roundThresholdModel(layers=layers_rnd, param_keys=[\"b\"], var_keys=[\"x\"],\n",
    "                         output_keys=[\"x_rnd\"], bin_ind={\"x\":range(500,1000)},\n",
    "                         continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = penaltyLoss([\"b\", \"x_rnd\"], A, c, lb, ub, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccced445-aa9e-4407-96e5-54abce448e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 550481920.00\n",
      "Epoch 0, Iters 125, Training Loss: 764715046.59, Validation Loss: 5288576512.00\n",
      "Epoch 1, Iters 250, Training Loss: 12041322.71, Validation Loss: 8907435008.00\n",
      "Epoch 2, Iters 375, Training Loss: 6207522.75, Validation Loss: 53237768.00\n",
      "Epoch 3, Iters 500, Training Loss: 4347348.97, Validation Loss: 10391225.00\n",
      "Epoch 4, Iters 625, Training Loss: 2163679.33, Validation Loss: 1914122.38\n",
      "Epoch 5, Iters 750, Training Loss: 1153254.93, Validation Loss: 1388604.38\n",
      "Epoch 6, Iters 875, Training Loss: 764870.13, Validation Loss: 1015742.00\n",
      "Epoch 7, Iters 1000, Training Loss: 440013.08, Validation Loss: 159021.08\n",
      "Epoch 8, Iters 1125, Training Loss: 209666.23, Validation Loss: 97752.07\n",
      "Epoch 9, Iters 1250, Training Loss: 141503.77, Validation Loss: 17876.20\n",
      "Epoch 10, Iters 1375, Training Loss: 95728.27, Validation Loss: 5283.40\n",
      "Epoch 11, Iters 1500, Training Loss: 17759.89, Validation Loss: 47334.52\n",
      "Epoch 12, Iters 1625, Training Loss: 7240.76, Validation Loss: -1640.55\n",
      "Epoch 13, Iters 1750, Training Loss: 4651.62, Validation Loss: -1979.20\n",
      "Epoch 14, Iters 1875, Training Loss: 6145.15, Validation Loss: -2801.68\n",
      "Epoch 15, Iters 2000, Training Loss: 3439.62, Validation Loss: -2493.82\n",
      "Epoch 16, Iters 2125, Training Loss: 4.05, Validation Loss: 2709.40\n",
      "Epoch 17, Iters 2250, Training Loss: -146.30, Validation Loss: -2311.54\n",
      "Epoch 18, Iters 2375, Training Loss: 2608.93, Validation Loss: -2874.48\n",
      "Epoch 19, Iters 2500, Training Loss: -1659.47, Validation Loss: -2928.01\n",
      "Epoch 20, Iters 2625, Training Loss: -891.59, Validation Loss: -3353.72\n",
      "Epoch 21, Iters 2750, Training Loss: 4512.31, Validation Loss: 25173.65\n",
      "Epoch 22, Iters 2875, Training Loss: -909.23, Validation Loss: 1020.37\n",
      "Epoch 23, Iters 3000, Training Loss: -4201.33, Validation Loss: -3559.92\n",
      "Epoch 24, Iters 3125, Training Loss: 1679.09, Validation Loss: -3300.19\n",
      "Epoch 25, Iters 3250, Training Loss: 1335.67, Validation Loss: -4779.45\n",
      "Epoch 26, Iters 3375, Training Loss: -542.21, Validation Loss: 204631.53\n",
      "Epoch 27, Iters 3500, Training Loss: -1853.76, Validation Loss: 332.92\n",
      "Epoch 28, Iters 3625, Training Loss: -3554.24, Validation Loss: 9072.37\n",
      "Epoch 29, Iters 3750, Training Loss: 1861.43, Validation Loss: -4241.45\n",
      "Epoch 30, Iters 3875, Training Loss: -2026.33, Validation Loss: -2379.04\n",
      "Epoch 31, Iters 4000, Training Loss: -758.21, Validation Loss: 219.39\n",
      "Epoch 32, Iters 4125, Training Loss: 2278.35, Validation Loss: -1873.90\n",
      "Epoch 33, Iters 4250, Training Loss: 6246.61, Validation Loss: -4011.73\n",
      "Epoch 34, Iters 4375, Training Loss: 7731.98, Validation Loss: 56653.54\n",
      "Epoch 35, Iters 4500, Training Loss: 2713.76, Validation Loss: -4793.03\n",
      "Epoch 36, Iters 4625, Training Loss: -4687.19, Validation Loss: -1464.20\n",
      "Epoch 37, Iters 4750, Training Loss: -4494.75, Validation Loss: 28864.37\n",
      "Epoch 38, Iters 4875, Training Loss: 426.84, Validation Loss: -6401.40\n",
      "Epoch 39, Iters 5000, Training Loss: -4005.61, Validation Loss: 4953.88\n",
      "Epoch 40, Iters 5125, Training Loss: -142.15, Validation Loss: -6138.57\n",
      "Epoch 41, Iters 5250, Training Loss: -2207.81, Validation Loss: -4018.68\n",
      "Epoch 42, Iters 5375, Training Loss: -1484.08, Validation Loss: 14240.44\n",
      "Epoch 43, Iters 5500, Training Loss: 585.93, Validation Loss: -5669.07\n",
      "Epoch 44, Iters 5625, Training Loss: 404.41, Validation Loss: 5675.83\n",
      "Epoch 45, Iters 5750, Training Loss: 409.26, Validation Loss: -5802.97\n",
      "Epoch 46, Iters 5875, Training Loss: 1843.23, Validation Loss: 79143.98\n",
      "Epoch 47, Iters 6000, Training Loss: -4813.09, Validation Loss: -7072.06\n",
      "Epoch 48, Iters 6125, Training Loss: 76453.66, Validation Loss: -7180.74\n",
      "Epoch 49, Iters 6250, Training Loss: 1043.22, Validation Loss: -6056.52\n",
      "Epoch 50, Iters 6375, Training Loss: 816.24, Validation Loss: -7266.06\n",
      "Epoch 51, Iters 6500, Training Loss: 420.72, Validation Loss: -7157.89\n",
      "Epoch 52, Iters 6625, Training Loss: 5820.37, Validation Loss: -5285.10\n",
      "Epoch 53, Iters 6750, Training Loss: 95414.22, Validation Loss: 99339.66\n",
      "Epoch 54, Iters 6875, Training Loss: 48217.12, Validation Loss: -7265.05\n",
      "Epoch 55, Iters 7000, Training Loss: 39791.85, Validation Loss: -7407.84\n",
      "Epoch 56, Iters 7125, Training Loss: 7757.04, Validation Loss: -7770.24\n",
      "Epoch 57, Iters 7250, Training Loss: 30056.57, Validation Loss: 328740.25\n",
      "Epoch 58, Iters 7375, Training Loss: 20409.96, Validation Loss: -6832.78\n",
      "Epoch 59, Iters 7500, Training Loss: 6757.69, Validation Loss: -4893.42\n",
      "Epoch 60, Iters 7625, Training Loss: 19303.90, Validation Loss: -7298.11\n",
      "Epoch 61, Iters 7750, Training Loss: 6803.43, Validation Loss: -6998.55\n",
      "Epoch 62, Iters 7875, Training Loss: 24582.07, Validation Loss: -7611.17\n",
      "Epoch 63, Iters 8000, Training Loss: 5426.40, Validation Loss: -7091.29\n",
      "Epoch 64, Iters 8125, Training Loss: 7602.03, Validation Loss: -7794.91\n",
      "Epoch 65, Iters 8250, Training Loss: -5701.84, Validation Loss: -7021.61\n",
      "Epoch 66, Iters 8375, Training Loss: 18926.86, Validation Loss: -6217.02\n",
      "Epoch 67, Iters 8500, Training Loss: -4084.76, Validation Loss: -8298.80\n",
      "Epoch 68, Iters 8625, Training Loss: -3348.68, Validation Loss: -7441.33\n",
      "Epoch 69, Iters 8750, Training Loss: 10809.60, Validation Loss: -7657.69\n",
      "Epoch 70, Iters 8875, Training Loss: -693.28, Validation Loss: -6888.10\n",
      "Epoch 71, Iters 9000, Training Loss: 9039.63, Validation Loss: -8030.03\n",
      "Epoch 72, Iters 9125, Training Loss: 15000.80, Validation Loss: 6127.60\n",
      "Epoch 73, Iters 9250, Training Loss: 12457.51, Validation Loss: 345934.72\n",
      "Epoch 74, Iters 9375, Training Loss: 8902.77, Validation Loss: -7056.37\n",
      "Epoch 75, Iters 9500, Training Loss: -4033.63, Validation Loss: -2951.18\n",
      "Epoch 76, Iters 9625, Training Loss: -2046.79, Validation Loss: -6615.59\n",
      "Epoch 77, Iters 9750, Training Loss: 63451.95, Validation Loss: -8083.43\n",
      "Epoch 78, Iters 9875, Training Loss: 8360.23, Validation Loss: -8242.47\n",
      "Epoch 79, Iters 10000, Training Loss: 14254.30, Validation Loss: -2356.77\n",
      "Epoch 80, Iters 10125, Training Loss: 12702.72, Validation Loss: 636.00\n",
      "Epoch 81, Iters 10250, Training Loss: -1519.66, Validation Loss: -7995.69\n",
      "Epoch 82, Iters 10375, Training Loss: 7683.47, Validation Loss: -8607.58\n",
      "Epoch 83, Iters 10500, Training Loss: 11163.94, Validation Loss: -4430.70\n",
      "Epoch 84, Iters 10625, Training Loss: 3094.25, Validation Loss: -8734.30\n",
      "Epoch 85, Iters 10750, Training Loss: 13990.35, Validation Loss: -8217.68\n",
      "Epoch 86, Iters 10875, Training Loss: -20.24, Validation Loss: -7761.66\n",
      "Epoch 87, Iters 11000, Training Loss: -3269.05, Validation Loss: -8579.22\n",
      "Epoch 88, Iters 11125, Training Loss: -6079.58, Validation Loss: -8817.56\n",
      "Epoch 89, Iters 11250, Training Loss: 29896.97, Validation Loss: -8165.02\n",
      "Epoch 90, Iters 11375, Training Loss: -6359.03, Validation Loss: -7461.32\n",
      "Epoch 91, Iters 11500, Training Loss: -4240.66, Validation Loss: -8436.52\n",
      "Epoch 92, Iters 11625, Training Loss: -4569.24, Validation Loss: -8610.17\n",
      "Epoch 93, Iters 11750, Training Loss: 10256.77, Validation Loss: -8764.58\n",
      "Epoch 94, Iters 11875, Training Loss: 4918.35, Validation Loss: -8923.42\n",
      "Epoch 95, Iters 12000, Training Loss: 10209.20, Validation Loss: -8161.02\n",
      "Epoch 96, Iters 12125, Training Loss: 6896.28, Validation Loss: -7561.67\n",
      "Epoch 97, Iters 12250, Training Loss: 1331.68, Validation Loss: -6455.12\n",
      "Epoch 98, Iters 12375, Training Loss: -6554.12, Validation Loss: -5257.96\n",
      "Epoch 99, Iters 12500, Training Loss: 80376.41, Validation Loss: -8950.70\n",
      "Epoch 100, Iters 12625, Training Loss: 31086.03, Validation Loss: -7735.63\n",
      "Epoch 101, Iters 12750, Training Loss: -7222.81, Validation Loss: -8636.70\n",
      "Epoch 102, Iters 12875, Training Loss: 6029.11, Validation Loss: -8925.38\n",
      "Epoch 103, Iters 13000, Training Loss: -5447.05, Validation Loss: -8910.26\n",
      "Epoch 104, Iters 13125, Training Loss: 443.54, Validation Loss: -7116.90\n",
      "Epoch 105, Iters 13250, Training Loss: 13059.12, Validation Loss: -4068.81\n",
      "Epoch 106, Iters 13375, Training Loss: -5405.56, Validation Loss: -8831.54\n",
      "Epoch 107, Iters 13500, Training Loss: -7159.18, Validation Loss: -9208.21\n",
      "Epoch 108, Iters 13625, Training Loss: 11213.75, Validation Loss: -8532.40\n",
      "Epoch 109, Iters 13750, Training Loss: -3862.53, Validation Loss: -7387.12\n",
      "Epoch 110, Iters 13875, Training Loss: -1251.71, Validation Loss: -9218.31\n",
      "Epoch 111, Iters 14000, Training Loss: -1550.66, Validation Loss: -8663.91\n",
      "Epoch 112, Iters 14125, Training Loss: -4762.31, Validation Loss: -9123.51\n",
      "Epoch 113, Iters 14250, Training Loss: 12683.92, Validation Loss: -8611.54\n",
      "Epoch 114, Iters 14375, Training Loss: 5119.41, Validation Loss: -9187.65\n",
      "Epoch 115, Iters 14500, Training Loss: 2651.67, Validation Loss: -7562.55\n",
      "Epoch 116, Iters 14625, Training Loss: 27872.20, Validation Loss: 814805.00\n",
      "Epoch 117, Iters 14750, Training Loss: 110516.85, Validation Loss: -1376.93\n",
      "Epoch 118, Iters 14875, Training Loss: 21258.84, Validation Loss: -8326.66\n",
      "Epoch 119, Iters 15000, Training Loss: -6830.93, Validation Loss: -9202.00\n",
      "Epoch 120, Iters 15125, Training Loss: 43677.03, Validation Loss: 874980.44\n",
      "Epoch 121, Iters 15250, Training Loss: 79173.68, Validation Loss: -8784.80\n",
      "Epoch 122, Iters 15375, Training Loss: 32847.69, Validation Loss: -5323.02\n",
      "Epoch 123, Iters 15500, Training Loss: 40027.59, Validation Loss: -9260.08\n",
      "Epoch 124, Iters 15625, Training Loss: 66880.81, Validation Loss: -9153.29\n",
      "Epoch 125, Iters 15750, Training Loss: 28677.88, Validation Loss: 914083.19\n",
      "Epoch 126, Iters 15875, Training Loss: -265.85, Validation Loss: -9264.91\n",
      "Epoch 127, Iters 16000, Training Loss: 109253.12, Validation Loss: -8735.28\n",
      "Epoch 128, Iters 16125, Training Loss: 1170.42, Validation Loss: -8876.45\n",
      "Epoch 129, Iters 16250, Training Loss: 23475.59, Validation Loss: -6403.29\n",
      "Epoch 130, Iters 16375, Training Loss: 83219.26, Validation Loss: -8031.93\n",
      "Epoch 131, Iters 16500, Training Loss: 87572.07, Validation Loss: -8832.00\n",
      "Epoch 132, Iters 16625, Training Loss: 13538.89, Validation Loss: -8905.43\n",
      "Epoch 133, Iters 16750, Training Loss: 13521.51, Validation Loss: -9150.61\n",
      "Epoch 134, Iters 16875, Training Loss: -4341.02, Validation Loss: -8474.84\n",
      "Epoch 135, Iters 17000, Training Loss: -3398.68, Validation Loss: -8999.91\n",
      "Epoch 136, Iters 17125, Training Loss: 19789.19, Validation Loss: -8863.68\n",
      "Epoch 137, Iters 17250, Training Loss: 30512.02, Validation Loss: -8911.33\n",
      "Epoch 138, Iters 17375, Training Loss: 31491.84, Validation Loss: 118357.05\n",
      "Epoch 139, Iters 17500, Training Loss: 180547.12, Validation Loss: 854162.50\n",
      "Epoch 140, Iters 17625, Training Loss: 50805.39, Validation Loss: -6972.45\n",
      "Epoch 141, Iters 17750, Training Loss: 81091.89, Validation Loss: -8741.81\n",
      "Epoch 142, Iters 17875, Training Loss: 6032.50, Validation Loss: -2775.57\n",
      "Epoch 143, Iters 18000, Training Loss: 36528.13, Validation Loss: -8888.70\n",
      "Epoch 144, Iters 18125, Training Loss: 101789.62, Validation Loss: -8954.10\n",
      "Epoch 145, Iters 18250, Training Loss: 4344.35, Validation Loss: 16486.45\n",
      "Epoch 146, Iters 18375, Training Loss: 22182.04, Validation Loss: -9135.80\n",
      "Epoch 147, Iters 18500, Training Loss: 62779.18, Validation Loss: -6325.20\n",
      "Epoch 148, Iters 18625, Training Loss: 833.68, Validation Loss: 131015.19\n",
      "Epoch 149, Iters 18750, Training Loss: 86602.01, Validation Loss: -8698.53\n",
      "Epoch 150, Iters 18875, Training Loss: 80418.82, Validation Loss: -4881.54\n",
      "Epoch 151, Iters 19000, Training Loss: 84880.06, Validation Loss: -8910.87\n",
      "Epoch 152, Iters 19125, Training Loss: 82586.80, Validation Loss: -8697.50\n",
      "Epoch 153, Iters 19250, Training Loss: 173066.63, Validation Loss: -8924.66\n",
      "Epoch 154, Iters 19375, Training Loss: 1247.76, Validation Loss: -8795.05\n",
      "Epoch 155, Iters 19500, Training Loss: 92531.54, Validation Loss: 9810.76\n",
      "Epoch 156, Iters 19625, Training Loss: 120208.91, Validation Loss: 3397.40\n",
      "Epoch 157, Iters 19750, Training Loss: 79357.04, Validation Loss: 137943.23\n",
      "Epoch 158, Iters 19875, Training Loss: 158755.20, Validation Loss: -8147.72\n",
      "Epoch 159, Iters 20000, Training Loss: 79705.56, Validation Loss: -5449.93\n",
      "Epoch 160, Iters 20125, Training Loss: 117549.37, Validation Loss: 113870.58\n",
      "Epoch 161, Iters 20250, Training Loss: 23551.56, Validation Loss: -9194.77\n",
      "Epoch 162, Iters 20375, Training Loss: 97607.26, Validation Loss: -7843.36\n",
      "Epoch 163, Iters 20500, Training Loss: 48831.18, Validation Loss: -9140.97\n",
      "Epoch 164, Iters 20625, Training Loss: 2854.90, Validation Loss: -5897.08\n",
      "Epoch 165, Iters 20750, Training Loss: 199747.54, Validation Loss: -8422.32\n",
      "Epoch 166, Iters 20875, Training Loss: 127789.56, Validation Loss: -6625.54\n",
      "Early stopping at iters 20875\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 337.24 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 400                    # number of training epochs\n",
    "warmup = 40                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 40                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c786ef9c-a2fc-48e7-8cb8-d8b7981adab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:46<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Mean Violation  Max Violation  Num Violations  \\\n",
      "count    10.000000       10.000000      10.000000       10.000000   \n",
      "mean  -9389.013899        0.000825       0.029711      159.400000   \n",
      "std       1.532557        0.000005       0.001032        0.966092   \n",
      "min   -9390.438238        0.000816       0.028864      158.000000   \n",
      "25%   -9390.173421        0.000821       0.029016      159.000000   \n",
      "50%   -9389.727776        0.000826       0.029214      159.000000   \n",
      "75%   -9387.756657        0.000827       0.030331      159.750000   \n",
      "max   -9386.669977        0.000834       0.031670      161.000000   \n",
      "\n",
      "       Elapsed Time  \n",
      "count     10.000000  \n",
      "mean       0.005207  \n",
      "std        0.001187  \n",
      "min        0.004030  \n",
      "25%        0.004574  \n",
      "50%        0.004805  \n",
      "75%        0.005559  \n",
      "max        0.008009  \n",
      "Total elapsed time for optimization: 0.05 seconds\n",
      "Number of infeasible solution: 10\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = gp.read(\"temp.mps\")\n",
    "# init df\n",
    "params, sols, objvals, mean_viols, max_viols, num_viols, elapseds = [], [], [], [], [], [], []\n",
    "for b in tqdm(test_data):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"b\": torch.unsqueeze(torch.tensor(b).float()[:250], 0).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # get solutions\n",
    "    x_val = datapoints[\"x_rnd\"][0].detach().cpu().numpy()\n",
    "    obj, viol = evaluateModel(model, x_val)\n",
    "    # record\n",
    "    params.append(list(b[:250]))\n",
    "    sols.append(x_val)\n",
    "    objvals.append(obj)\n",
    "    mean_viols.append(np.mean(viol))\n",
    "    max_viols.append(np.max(viol))\n",
    "    num_viols.append(np.sum(viol > 1e-6))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\": params,\n",
    "                   \"Sol\": sols,\n",
    "                   \"Obj Val\": objvals,\n",
    "                   \"Mean Violation\": mean_viols,\n",
    "                   \"Max Violation\": max_viols,\n",
    "                   \"Num Violations\": num_viols,\n",
    "                   \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Total elapsed time for optimization: {:.2f} seconds\".format(df[\"Elapsed Time\"].sum()))\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Num Violations\"] > 0)))\n",
    "df.to_csv(\"result/lp_thd_rhs-series2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e64ef8-a066-42ac-899b-17a6d3fa9552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
