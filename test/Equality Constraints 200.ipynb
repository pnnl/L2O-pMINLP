{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f1d1e6-de38-41a6-af20-1a60148eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f4f8e-9145-4d00-996d-d0e2fce26db5",
   "metadata": {},
   "source": [
    "### Define Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc1b4d2-c7f9-467c-92cf-c7daf66cca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class penaltyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Penalty loss function for Rosenbrock problem\n",
    "    \"\"\"\n",
    "    def __init__(self, input_keys, steepness, num_blocks, penalty_weight=50, output_key=\"loss\"):\n",
    "        super().__init__()\n",
    "        self.p_key, self.a_key, self.x_key = input_keys\n",
    "        self.output_key = output_key\n",
    "        self.steepness = steepness\n",
    "        self.num_blocks = num_blocks\n",
    "        self.penalty_weight = penalty_weight\n",
    "        self.device = None\n",
    "        # coef\n",
    "        rng = np.random.RandomState(17)\n",
    "        b = rng.normal(scale=1, size=(num_blocks))\n",
    "        q = rng.normal(scale=1, size=(num_blocks))\n",
    "        self.b = torch.from_numpy(b).float()\n",
    "        self.q = torch.from_numpy(q).float()\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        \"\"\"\n",
    "        forward pass\n",
    "        \"\"\"\n",
    "        # objective function\n",
    "        obj = self.cal_obj(input_dict)\n",
    "        # constraints violation\n",
    "        viol = self.cal_constr_viol(input_dict)\n",
    "        # penalized loss\n",
    "        loss = obj + self.penalty_weight * viol\n",
    "        input_dict[self.output_key] = torch.mean(loss)\n",
    "        return input_dict\n",
    "\n",
    "    def cal_obj(self, input_dict):\n",
    "        \"\"\"\n",
    "        calculate objective function\n",
    "        \"\"\"\n",
    "        # get values\n",
    "        x, a = input_dict[self.x_key], input_dict[self.a_key]\n",
    "        # x_2i\n",
    "        x1 = x[:, ::2]\n",
    "        # x_2i+1\n",
    "        x2 = x[:, 1::2]\n",
    "        # objective function\n",
    "        f = torch.sum((a - x1) ** 2 + self.steepness * (x2 - x1 ** 2) ** 2, dim=1)\n",
    "        return f\n",
    "\n",
    "    def cal_constr_viol(self, input_dict):\n",
    "        \"\"\"\n",
    "        calculate constraints violation\n",
    "        \"\"\"\n",
    "        # get values\n",
    "        x, p = input_dict[self.x_key], input_dict[self.p_key]\n",
    "        # update device\n",
    "        if self.device is None:\n",
    "            self.device = x.device\n",
    "            self.b = self.b.to(self.device)\n",
    "            self.q = self.q.to(self.device)\n",
    "        # inner constraint violation\n",
    "        lhs_inner = torch.sum(x[:, 1::2], dim=1)\n",
    "        rhs_inner = self.num_blocks * p[:, 0] / 2\n",
    "        inner_violation = torch.relu(rhs_inner - lhs_inner)\n",
    "        # outer constraint violation\n",
    "        lhs_outer = torch.sum(x[:, ::2] ** 2, dim=1)\n",
    "        rhs_outer = self.num_blocks * p[:, 0]\n",
    "        outer_violation = torch.relu(lhs_outer - rhs_outer)\n",
    "        # lear constraint violation\n",
    "        lhs_1 = torch.matmul(x[:, 0::2], self.b)\n",
    "        lhs_2 = torch.matmul(x[:, 1::2], self.q)\n",
    "        linear_violation = torch.abs(lhs_1) + torch.abs(lhs_2)\n",
    "        return inner_violation + outer_violation + linear_violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f873aad0-1ee5-4bac-89d2-4eb22e063418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyomo import environ as pe\n",
    "from src.problem.math_solver import abcParamSolver\n",
    "\n",
    "class rosenbrock(abcParamSolver):\n",
    "    def __init__(self, steepness, num_blocks, timelimit=None):\n",
    "        super().__init__(timelimit=timelimit)\n",
    "        # create model\n",
    "        m = pe.ConcreteModel()\n",
    "        # parameters\n",
    "        m.p = pe.Param(default=1, mutable=True)\n",
    "        m.a = pe.Param(pe.RangeSet(0, num_blocks-1), default=1, mutable=True)\n",
    "        # variables\n",
    "        m.x = pe.Var(pe.RangeSet(0, num_blocks*2-1), domain=pe.Reals)\n",
    "        for i in range(num_blocks):\n",
    "            # integer variables\n",
    "            m.x[2*i+1].domain = pe.Integers\n",
    "        # objective\n",
    "        obj = sum((m.a[i] - m.x[2*i]) ** 2 + \\\n",
    "                   steepness * (m.x[2*i+1] - m.x[2*i] ** 2) ** 2 for i in range(num_blocks))\n",
    "        m.obj = pe.Objective(sense=pe.minimize, expr=obj)\n",
    "        # constraints\n",
    "        m.cons = pe.ConstraintList()\n",
    "        m.cons.add(sum(m.x[2*i+1] for i in range(num_blocks)) >= num_blocks * m.p / 2)\n",
    "        m.cons.add(sum(m.x[2*i] ** 2 for i in range(num_blocks)) <= num_blocks * m.p)\n",
    "        rng = np.random.RandomState(17)\n",
    "        b = rng.normal(scale=1, size=(num_blocks))\n",
    "        q = rng.normal(scale=1, size=(num_blocks))\n",
    "        m.cons.add(sum(b[i] * m.x[2*i] for i in range(num_blocks)) == 0)\n",
    "        m.cons.add(sum(q[i] * m.x[2*i+1] for i in range(num_blocks)) == 0)\n",
    "        # attribute\n",
    "        self.model = m\n",
    "        self.params ={\"p\":m.p, \"a\":m.a}\n",
    "        self.vars = {\"x\":m.x}\n",
    "        self.cons = m.cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e876505-51b6-4011-ae8a-b27459a6e971",
   "metadata": {},
   "source": [
    "### Problem Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78e3dd1-f9be-438f-9b40-6745f4f285af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "steepness = 50    # steepness factor\n",
    "num_blocks = 100  # number of expression blocks\n",
    "num_data = 9100   # number of data\n",
    "test_size = 100   # number of test size\n",
    "val_size = 1000   # number of validation size\n",
    "train_size = num_data - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d040f1a-56b0-4c94-ba7a-921c2c4d93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as input data\n",
    "p_low, p_high = 1.0, 8.0\n",
    "a_low, a_high = 0.5, 4.5\n",
    "p_train = np.random.uniform(p_low, p_high, (train_size, 1)).astype(np.float32)\n",
    "p_test  = np.random.uniform(p_low, p_high, (test_size, 1)).astype(np.float32)\n",
    "p_dev   = np.random.uniform(p_low, p_high, (val_size, 1)).astype(np.float32)\n",
    "a_train = np.random.uniform(a_low, a_high, (train_size, num_blocks)).astype(np.float32)\n",
    "a_test  = np.random.uniform(a_low, a_high, (test_size, num_blocks)).astype(np.float32)\n",
    "a_dev   = np.random.uniform(a_low, a_high, (val_size, num_blocks)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3ea095-2bd8-4ecc-ab73-ce42cb66b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm datasets\n",
    "from neuromancer.dataset import DictDataset\n",
    "data_train = DictDataset({\"p\":p_train, \"a\":a_train}, name=\"train\")\n",
    "data_test = DictDataset({\"p\":p_test, \"a\":a_test}, name=\"test\")\n",
    "data_dev = DictDataset({\"p\":p_dev, \"a\":a_dev}, name=\"dev\")\n",
    "# torch dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "loader_train = DataLoader(data_train, batch_size, num_workers=0, collate_fn=data_train.collate_fn, shuffle=True)\n",
    "loader_test = DataLoader(data_test, batch_size, num_workers=0, collate_fn=data_test.collate_fn, shuffle=False)\n",
    "loader_dev = DataLoader(data_dev, batch_size, num_workers=0, collate_fn=data_dev.collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0471af2-eb01-4b23-8cb0-204c23ac144a",
   "metadata": {},
   "source": [
    "### Exact Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55e7bf9-8897-49af-9719-fb77df0f349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.problem import msRosenbrock\n",
    "model = msRosenbrock(steepness, num_blocks, timelimit=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf896f-b041-4453-85f0-b8fdfdc0423f",
   "metadata": {},
   "source": [
    "### Rounding Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d38a02-c027-48e6-9205-08e3ad682dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ee933c-27af-4aa9-9fc2-8ceed279534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "penalty_weight = 100  # weight of constraint violation penealty\n",
    "hlayers_sol = 5       # number of hidden layers for solution mapping\n",
    "hlayers_rnd = 4       # number of hidden layers for solution mapping\n",
    "hsize = 64            # width of hidden layers for solution mapping\n",
    "lr = 1e-3             # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b89626-b966-42de-89e4-08689910b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set problem\n",
    "import neuromancer as nm\n",
    "from src.problem import nmRosenbrock\n",
    "from src.func.layer import netFC\n",
    "from src.func import roundGumbelModel\n",
    "# build neural architecture for the solution map\n",
    "func = nm.modules.blocks.MLP(insize=num_blocks+1, outsize=2*num_blocks, bias=True,\n",
    "                             linear_map=nm.slim.maps[\"linear\"],\n",
    "                             nonlin=nn.ReLU, hsizes=[hsize]*hlayers_sol)\n",
    "smap = nm.system.Node(func, [\"p\", \"a\"], [\"x\"], name=\"smap\")\n",
    "# define rounding model\n",
    "layers_rnd = netFC(input_dim=3*num_blocks+1, hidden_dims=[hsize]*hlayers_rnd, output_dim=2*num_blocks)\n",
    "rnd = roundGumbelModel(layers=layers_rnd, param_keys=[\"p\", \"a\"], var_keys=[\"x\"],  output_keys=[\"x_rnd\"], \n",
    "                       int_ind=model.int_ind, continuous_update=True, name=\"round\")\n",
    "# build neuromancer problem for rounding\n",
    "components = nn.ModuleList([smap, rnd]).to(\"cuda\")\n",
    "loss_fn = nmRosenbrock([\"p\", \"a\", \"x_rnd\"], steepness, num_blocks, penalty_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53854d39-8dc3-4228-8c15-0c0e894d7595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iters 0, Validation Loss: 26030.72\n",
      "Epoch 0, Iters 125, Training Loss: 12555.93, Validation Loss: 2930.95\n",
      "Epoch 1, Iters 250, Training Loss: 2584.26, Validation Loss: 1616.89\n",
      "Epoch 2, Iters 375, Training Loss: 1969.03, Validation Loss: 1341.72\n",
      "Epoch 3, Iters 500, Training Loss: 1672.77, Validation Loss: 1513.75\n",
      "Epoch 4, Iters 625, Training Loss: 1631.33, Validation Loss: 1351.38\n",
      "Epoch 5, Iters 750, Training Loss: 1404.35, Validation Loss: 1042.79\n",
      "Epoch 6, Iters 875, Training Loss: 1247.25, Validation Loss: 924.95\n",
      "Epoch 7, Iters 1000, Training Loss: 1199.53, Validation Loss: 964.55\n",
      "Epoch 8, Iters 1125, Training Loss: 1149.10, Validation Loss: 845.01\n",
      "Epoch 9, Iters 1250, Training Loss: 1022.84, Validation Loss: 783.51\n",
      "Epoch 10, Iters 1375, Training Loss: 1004.38, Validation Loss: 762.00\n",
      "Epoch 11, Iters 1500, Training Loss: 921.31, Validation Loss: 783.09\n",
      "Epoch 12, Iters 1625, Training Loss: 857.59, Validation Loss: 611.56\n",
      "Epoch 13, Iters 1750, Training Loss: 809.16, Validation Loss: 642.49\n",
      "Epoch 14, Iters 1875, Training Loss: 782.49, Validation Loss: 597.33\n",
      "Epoch 15, Iters 2000, Training Loss: 818.07, Validation Loss: 622.12\n",
      "Epoch 16, Iters 2125, Training Loss: 780.57, Validation Loss: 617.11\n",
      "Epoch 17, Iters 2250, Training Loss: 777.43, Validation Loss: 614.68\n",
      "Epoch 18, Iters 2375, Training Loss: 737.94, Validation Loss: 609.82\n",
      "Epoch 19, Iters 2500, Training Loss: 735.01, Validation Loss: 619.65\n",
      "Epoch 20, Iters 2625, Training Loss: 843.10, Validation Loss: 753.51\n",
      "Epoch 21, Iters 2750, Training Loss: 817.20, Validation Loss: 674.03\n",
      "Epoch 22, Iters 2875, Training Loss: 768.27, Validation Loss: 679.90\n",
      "Epoch 23, Iters 3000, Training Loss: 814.93, Validation Loss: 585.54\n",
      "Epoch 24, Iters 3125, Training Loss: 761.43, Validation Loss: 638.27\n",
      "Epoch 25, Iters 3250, Training Loss: 760.50, Validation Loss: 539.36\n",
      "Epoch 26, Iters 3375, Training Loss: 782.08, Validation Loss: 832.26\n",
      "Epoch 27, Iters 3500, Training Loss: 784.83, Validation Loss: 870.48\n",
      "Epoch 28, Iters 3625, Training Loss: 807.04, Validation Loss: 664.35\n",
      "Epoch 29, Iters 3750, Training Loss: 791.44, Validation Loss: 662.53\n",
      "Epoch 30, Iters 3875, Training Loss: 828.88, Validation Loss: 677.52\n",
      "Epoch 31, Iters 4000, Training Loss: 857.79, Validation Loss: 855.23\n",
      "Epoch 32, Iters 4125, Training Loss: 914.45, Validation Loss: 859.61\n",
      "Epoch 33, Iters 4250, Training Loss: 890.43, Validation Loss: 746.04\n",
      "Epoch 34, Iters 4375, Training Loss: 823.27, Validation Loss: 563.47\n",
      "Epoch 35, Iters 4500, Training Loss: 816.27, Validation Loss: 981.35\n",
      "Epoch 36, Iters 4625, Training Loss: 816.28, Validation Loss: 615.30\n",
      "Epoch 37, Iters 4750, Training Loss: 815.13, Validation Loss: 588.14\n",
      "Epoch 38, Iters 4875, Training Loss: 840.71, Validation Loss: 855.73\n",
      "Epoch 39, Iters 5000, Training Loss: 807.62, Validation Loss: 578.78\n",
      "Epoch 40, Iters 5125, Training Loss: 806.94, Validation Loss: 622.57\n",
      "Epoch 41, Iters 5250, Training Loss: 808.22, Validation Loss: 605.77\n",
      "Epoch 42, Iters 5375, Training Loss: 801.91, Validation Loss: 740.20\n",
      "Epoch 43, Iters 5500, Training Loss: 819.07, Validation Loss: 732.08\n",
      "Epoch 44, Iters 5625, Training Loss: 825.20, Validation Loss: 803.74\n",
      "Epoch 45, Iters 5750, Training Loss: 827.97, Validation Loss: 587.15\n",
      "Early stopping at iters 5750\n",
      "Best model loaded.\n",
      "Training complete.\n",
      "The training time is 75.23 sec.\n"
     ]
    }
   ],
   "source": [
    "from src.problem.neuromancer.trainer import trainer\n",
    "# training\n",
    "epochs = 200                    # number of training epochs\n",
    "warmup = 20                     # number of epochs to wait before enacting early stopping policy\n",
    "patience = 20                   # number of epochs with no improvement in eval metric to allow before early stopping\n",
    "optimizer = torch.optim.AdamW(components.parameters(), lr=lr)\n",
    "# create a trainer for the problem\n",
    "my_trainer = trainer(components, loss_fn, optimizer, epochs=epochs, patience=patience, warmup=warmup, device=\"cuda\")\n",
    "# training for the rounding problem\n",
    "my_trainer.train(loader_train, loader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5740c26-8e56-4273-b194-c137dc105b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 60.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Obj Val  Mean Violation  Max Violation  Num Violations  \\\n",
      "count   100.000000      100.000000     100.000000          100.00   \n",
      "mean    505.468789        0.012428       0.049710            0.01   \n",
      "std     277.830401        0.124276       0.497105            0.10   \n",
      "min     205.342949        0.000000       0.000000            0.00   \n",
      "25%     275.317606        0.000000       0.000000            0.00   \n",
      "50%     439.786604        0.000000       0.000000            0.00   \n",
      "75%     649.349116        0.000000       0.000000            0.00   \n",
      "max    1594.439685        1.242761       4.971045            1.00   \n",
      "\n",
      "       Elapsed Time  \n",
      "count    100.000000  \n",
      "mean       0.002948  \n",
      "std        0.001076  \n",
      "min        0.001001  \n",
      "25%        0.002005  \n",
      "50%        0.002812  \n",
      "75%        0.003185  \n",
      "max        0.009028  \n",
      "Number of infeasible solution: 1\n"
     ]
    }
   ],
   "source": [
    "params, sols, objvals, mean_viols, max_viols, num_viols, elapseds = [], [], [], [], [], [], []\n",
    "for p, a in tqdm(list(zip(p_test, a_test))):\n",
    "    # data point as tensor\n",
    "    datapoints = {\"p\": torch.tensor(np.array([p]), dtype=torch.float32).to(\"cuda\"), \n",
    "                  \"a\": torch.tensor(np.array([a]), dtype=torch.float32).to(\"cuda\"),\n",
    "                  \"name\": \"test\"}\n",
    "    # infer\n",
    "    components.eval()\n",
    "    tick = time.time()\n",
    "    with torch.no_grad():\n",
    "        for comp in components:\n",
    "            datapoints.update(comp(datapoints))\n",
    "    tock = time.time()\n",
    "    # assign params\n",
    "    model.set_param_val({\"p\":p, \"a\":a})\n",
    "    # assign vars\n",
    "    x = datapoints[\"x_rnd\"]\n",
    "    for i in range(2*num_blocks):\n",
    "        model.vars[\"x\"][i].value = x[0,i].item()\n",
    "    # get solutions\n",
    "    xval, objval = model.get_val()    \n",
    "    params.append(list(p)+list(a))\n",
    "    sols.append(list(list(xval.values())[0].values()))\n",
    "    objvals.append(objval)\n",
    "    viol = model.cal_violation()\n",
    "    mean_viols.append(np.mean(viol))\n",
    "    max_viols.append(np.max(viol))\n",
    "    num_viols.append(np.sum(viol > 1e-6))\n",
    "    elapseds.append(tock - tick)\n",
    "df = pd.DataFrame({\"Param\": params,\n",
    "                    \"Sol\": sols,\n",
    "                    \"Obj Val\": objvals,\n",
    "                    \"Mean Violation\": mean_viols,\n",
    "                    \"Max Violation\": max_viols,\n",
    "                    \"Num Violations\": num_viols,\n",
    "                    \"Elapsed Time\": elapseds})\n",
    "time.sleep(1)\n",
    "print(df.describe())\n",
    "print(\"Number of infeasible solution: {}\".format(np.sum(df[\"Num Violations\"] > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb607baf-84df-47e4-9b87-3f5ba8995b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
